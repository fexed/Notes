\babel@toc {italian}{}
\babel@toc {italian}{}
\contentsline {section}{\numberline {0.1}Introduction}{2}{section.0.1}% 
\contentsline {chapter}{\numberline {1}Numerical Analysis}{3}{chapter.1}% 
\contentsline {section}{\numberline {1.1}Quick recap of linear algebra}{3}{section.1.1}% 
\contentsline {paragraph}{}{4}{section*.2}% 
\contentsline {paragraph}{Norms}{4}{section*.3}% 
\contentsline {paragraph}{Orthogonal}{4}{section*.4}% 
\contentsline {paragraph}{Eigenvalues and eigenvectors}{4}{section*.5}% 
\contentsline {paragraph}{Symmetry}{4}{section*.6}% 
\contentsline {paragraph}{Spectral Theorem}{4}{section*.7}% 
\contentsline {paragraph}{Quadratic form}{4}{section*.8}% 
\contentsline {paragraph}{Positive Semidefinite}{4}{section*.9}% 
\contentsline {paragraph}{Recall theorem}{4}{section*.10}% 
\contentsline {paragraph}{Generalization for complex matrices}{5}{section*.11}% 
\contentsline {section}{\numberline {1.2}SVD}{5}{section.1.2}% 
\contentsline {paragraph}{Singular Value Decomposition}{5}{section*.12}% 
\contentsline {subparagraph}{Geometric idea}{5}{section*.13}% 
\contentsline {subparagraph}{Rectangular SVD}{5}{section*.14}% 
\contentsline {subparagraph}{Cost in Malab}{5}{section*.15}% 
\contentsline {subparagraph}{Properties}{5}{section*.16}% 
\contentsline {paragraph}{Norms}{5}{section*.17}% 
\contentsline {subparagraph}{Properties of the Norms}{6}{section*.18}% 
\contentsline {paragraph}{Eckart-Young Theorem}{6}{section*.19}% 
\contentsline {paragraph}{Ranks}{6}{section*.20}% 
\contentsline {paragraph}{Excercise}{6}{section*.21}% 
\contentsline {subsection}{\numberline {1.2.1}SVD Approximation}{7}{subsection.1.2.1}% 
\contentsline {subparagraph}{Best approximations}{7}{section*.22}% 
\contentsline {paragraph}{Latent Semantic Analysis}{7}{section*.23}% 
\contentsline {paragraph}{Principal Component Analysis}{7}{section*.24}% 
\contentsline {section}{\numberline {1.3}(Linear) Least Squares problems}{8}{section.1.3}% 
\contentsline {paragraph}{Geometric View}{8}{section*.25}% 
\contentsline {paragraph}{Cases}{8}{section*.26}% 
\contentsline {paragraph}{Polynomial Fitting}{8}{section*.27}% 
\contentsline {paragraph}{Theory of Least-Squares Problems}{8}{section*.28}% 
\contentsline {subparagraph}{Theorem}{8}{section*.29}% 
\contentsline {subparagraph}{Algorithm}{9}{section*.30}% 
\contentsline {paragraph}{Pseudoinverse}{9}{section*.31}% 
\contentsline {section}{\numberline {1.4}QR factorization}{9}{section.1.4}% 
\contentsline {paragraph}{Geometric Picture}{9}{section*.32}% 
\contentsline {paragraph}{Lemma}{10}{section*.33}% 
\contentsline {paragraph}{Lemma}{10}{section*.34}% 
\contentsline {paragraph}{Numerical problems}{10}{section*.35}% 
\contentsline {paragraph}{Theorem}{10}{section*.36}% 
\contentsline {paragraph}{Optimizations}{11}{section*.37}% 
\contentsline {subparagraph}{Thin QR}{11}{section*.38}% 
\contentsline {paragraph}{Least Squares with QR}{12}{section*.39}% 
\contentsline {paragraph}{Least Squares with SVD}{13}{section*.40}% 
\contentsline {paragraph}{Special Solution}{13}{section*.41}% 
\contentsline {paragraph}{Effect of noise in data}{13}{section*.42}% 
\contentsline {paragraph}{Tikhonov Regularization/Ridge Regression}{14}{section*.43}% 
\contentsline {paragraph}{Sensitivity or conditioning of a problem}{14}{section*.44}% 
\contentsline {subparagraph}{Example}{14}{section*.45}% 
\contentsline {paragraph}{Relative Change}{14}{section*.46}% 
\contentsline {paragraph}{Condition Numbers in Linear Systems}{15}{section*.47}% 
\contentsline {paragraph}{Least Squares Problem}{15}{section*.48}% 
\contentsline {paragraph}{Theorem}{15}{section*.49}% 
\contentsline {paragraph}{Condition Number}{15}{section*.50}% 
\contentsline {section}{\numberline {1.5}Floating Point Numbers}{16}{section.1.5}% 
\contentsline {paragraph}{Quick recap}{16}{section*.51}% 
\contentsline {paragraph}{Error analysis}{16}{section*.52}% 
\contentsline {subparagraph}{Example}{16}{section*.53}% 
\contentsline {paragraph}{Backward Stability}{17}{section*.54}% 
\contentsline {subparagraph}{Theorem}{17}{section*.55}% 
\contentsline {paragraph}{Residuals and A-Posteriori Stability Checks}{17}{section*.56}% 
\contentsline {subparagraph}{Theorem}{18}{section*.57}% 
\contentsline {section}{\numberline {1.6}Algorithms for square linear systems $Ax=b$}{18}{section.1.6}% 
\contentsline {subsection}{\numberline {1.6.1}Gaussian Elimination}{18}{subsection.1.6.1}% 
\contentsline {paragraph}{Complexity}{18}{section*.58}% 
\contentsline {paragraph}{Storage problem}{18}{section*.59}% 
\contentsline {paragraph}{Idea}{18}{section*.60}% 
\contentsline {paragraph}{Stability}{18}{section*.61}% 
\contentsline {subparagraph}{Is LU plus pivoting stable?}{19}{section*.62}% 
\contentsline {subparagraph}{Another problem}{19}{section*.63}% 
\contentsline {subsection}{\numberline {1.6.2}Symmetric Gaussian Elimination}{19}{subsection.1.6.2}% 
\contentsline {subparagraph}{Theorem}{19}{section*.64}% 
\contentsline {subparagraph}{Lemma}{19}{section*.65}% 
\contentsline {subsection}{\numberline {1.6.3}Cholesky factorization}{19}{subsection.1.6.3}% 
\contentsline {subsection}{\numberline {1.6.4}Algorithms for solving linear systems}{20}{subsection.1.6.4}% 
\contentsline {subsection}{\numberline {1.6.5}Iterative Methods}{20}{subsection.1.6.5}% 
\contentsline {paragraph}{Idea}{20}{section*.66}% 
\contentsline {paragraph}{Krylov Subspace}{20}{section*.67}% 
\contentsline {paragraph}{}{21}{section*.68}% 
\contentsline {paragraph}{Arnoldi Algorithm}{21}{section*.69}% 
\contentsline {subparagraph}{Idea}{21}{section*.70}% 
\contentsline {subparagraph}{Factorization}{21}{section*.71}% 
\contentsline {subparagraph}{Breakdown}{22}{section*.72}% 
\contentsline {paragraph}{Theorem}{22}{section*.73}% 
\contentsline {subparagraph}{Complexity of Arnoldi}{22}{section*.74}% 
\contentsline {paragraph}{GMRES}{22}{section*.75}% 
\contentsline {subparagraph}{Convergence of GMRES}{22}{section*.76}% 
\contentsline {subsection}{\numberline {1.6.6}Conjugate Gradient}{23}{subsection.1.6.6}% 
\contentsline {paragraph}{Conjugate}{23}{section*.77}% 
\contentsline {paragraph}{Conjugate Gradient}{23}{section*.78}% 
\contentsline {paragraph}{Krylov subspace relations}{24}{section*.79}% 
\contentsline {paragraph}{Theorem}{24}{section*.80}% 
\contentsline {paragraph}{Theorem}{25}{section*.81}% 
\contentsline {paragraph}{Theorem}{25}{section*.82}% 
\contentsline {paragraph}{Convergence of CG}{25}{section*.83}% 
\contentsline {paragraph}{Linear Solvers}{26}{section*.84}% 
\contentsline {subsection}{\numberline {1.6.7}Solving Sparse Linear Systems}{26}{subsection.1.6.7}% 
\contentsline {paragraph}{Preconditioning}{26}{section*.85}% 
\contentsline {subparagraph}{Incomplete $LU$}{26}{section*.86}% 
\contentsline {paragraph}{Symmetric Preconditioning}{26}{section*.87}% 
\contentsline {chapter}{\numberline {2}Optimization}{27}{chapter.2}% 
\contentsline {subparagraph}{Example: Linear estimation}{27}{section*.88}% 
\contentsline {subparagraph}{Example: Low-rank approximation}{27}{section*.89}% 
\contentsline {subparagraph}{Example: Support Vector Machines}{28}{section*.90}% 
\contentsline {section}{\numberline {2.1}Optimization problems}{28}{section.2.1}% 
\contentsline {paragraph}{Multi-objective optimization}{28}{section*.91}% 
\contentsline {subsection}{\numberline {2.1.1}Optimization is hard}{29}{subsection.2.1.1}% 
\contentsline {paragraph}{Optimization need to be approximate}{29}{section*.92}% 
\contentsline {paragraph}{Optimization is really hard}{29}{section*.93}% 
\contentsline {paragraph}{Optimization at least possible}{29}{section*.94}% 
\contentsline {subsection}{\numberline {2.1.2}Local Optimization}{29}{subsection.2.1.2}% 
\contentsline {paragraph}{Optimally choosing the iterates}{30}{section*.95}% 
\contentsline {paragraph}{To make it go faster, give it more information}{31}{section*.96}% 
\contentsline {paragraph}{Dichotomic Search}{31}{section*.97}% 
\contentsline {paragraph}{Extreme value theorem}{32}{section*.98}% 
\contentsline {paragraph}{Fastest local optimization}{32}{section*.99}% 
\contentsline {subsection}{\numberline {2.1.3}Measuring algorithms speed}{32}{subsection.2.1.3}% 
\contentsline {paragraph}{Improving dichotomic search}{32}{section*.100}% 
\contentsline {paragraph}{Newton's method}{33}{section*.101}% 
\contentsline {subsection}{\numberline {2.1.4}Global optimization}{33}{subsection.2.1.4}% 
\contentsline {paragraph}{Convexity}{33}{section*.102}% 
\contentsline {section}{\numberline {2.2}Unconstrained optimization}{33}{section.2.2}% 
\contentsline {subparagraph}{Unconstraint global optimization}{34}{section*.103}% 
\contentsline {paragraph}{Notation}{34}{section*.104}% 
\contentsline {paragraph}{Tomography}{34}{section*.105}% 
\contentsline {paragraph}{Simple Functions}{34}{section*.106}% 
\contentsline {paragraph}{Directional/partial derivatives}{35}{section*.107}% 
\contentsline {paragraph}{Jacobian}{35}{section*.108}% 
\contentsline {paragraph}{Hessian}{35}{section*.109}% 
\contentsline {subparagraph}{Theorem}{36}{section*.110}% 
\contentsline {subsection}{\numberline {2.2.1}Optimality conditions}{36}{subsection.2.2.1}% 
\contentsline {subsection}{\numberline {2.2.2}Convex functions}{36}{subsection.2.2.2}% 
\contentsline {subsection}{\numberline {2.2.3}Gradient Methods}{36}{subsection.2.2.3}% 
\contentsline {paragraph}{Multivariate optimization algorithms}{36}{section*.111}% 
\contentsline {paragraph}{First order model $\Leftrightarrow $ gradient method}{36}{section*.112}% 
\contentsline {paragraph}{Step selection}{37}{section*.113}% 
\contentsline {paragraph}{Gradient for quadratic functions}{37}{section*.114}% 
\contentsline {subparagraph}{Analysis}{37}{section*.115}% 
\contentsline {paragraph}{When linear convergence may not be enough}{37}{section*.116}% 
\contentsline {subsubsection}{Gradient methods for general functions}{37}{section*.117}% 
\contentsline {paragraph}{Notes on the stopping criterion}{38}{section*.118}% 
\contentsline {paragraph}{Efficiency}{38}{section*.119}% 
\contentsline {subsubsection}{Fixed Stepsize}{38}{section*.120}% 
\contentsline {paragraph}{L-smoothness}{38}{section*.121}% 
\contentsline {paragraph}{Stronger forms of convexity}{39}{section*.122}% 
\contentsline {paragraph}{Convergence rate with strong convexity}{39}{section*.123}% 
\contentsline {subsubsection}{Inexact Line Search}{39}{section*.124}% 
\contentsline {paragraph}{Armijo}{39}{section*.125}% 
\contentsline {paragraph}{Wolfe}{39}{section*.126}% 
\contentsline {paragraph}{Armijo-Wolfe in practice}{40}{section*.127}% 
\contentsline {subsection}{\numberline {2.2.4}More-Than-Gradient Methods}{40}{subsection.2.2.4}% 
\contentsline {paragraph}{General descent methods}{40}{section*.128}% 
\contentsline {subparagraph}{Convergence of general descent methods}{40}{section*.129}% 
\contentsline {paragraph}{Newton's Method}{40}{section*.130}% 
\contentsline {paragraph}{Globalized Newton}{41}{section*.131}% 
\contentsline {subparagraph}{Theorem 1}{41}{section*.132}% 
\contentsline {subparagraph}{Theorem 2}{41}{section*.133}% 
\contentsline {subparagraph}{Theorem 3}{41}{section*.134}% 
\contentsline {subparagraph}{Nonconvex case}{41}{section*.135}% 
\contentsline {paragraph}{Trust Region}{42}{section*.136}% 
\contentsline {paragraph}{Quasi-Newton}{42}{section*.137}% 
\contentsline {paragraph}{DFP}{43}{section*.138}% 
\contentsline {paragraph}{BFGS}{43}{section*.139}% 
\contentsline {paragraph}{Conjugate gradient method for quadratic functions}{43}{section*.140}% 
\contentsline {subparagraph}{Convergence and efficiency}{43}{section*.141}% 
\contentsline {paragraph}{Deflected Gradients methods}{43}{section*.142}% 
\contentsline {subparagraph}{Heavy Ball Gradient}{44}{section*.143}% 
\contentsline {subparagraph}{Accelerated Gradient}{44}{section*.144}% 
\contentsline {subsection}{\numberline {2.2.5}Less-Than-Gradient Methods}{44}{subsection.2.2.5}% 
\contentsline {paragraph}{Stochastic Gradient}{44}{section*.145}% 
\contentsline {paragraph}{Nondifferentiable functions}{44}{section*.146}% 
\contentsline {paragraph}{Smooth methods fail on nonsmooth functions}{45}{section*.147}% 
\contentsline {subsubsection}{Convex Nondifferentiable Functions}{45}{section*.148}% 
\contentsline {paragraph}{Subgradients and subdifferentials}{45}{section*.149}% 
\contentsline {paragraph}{Subgradients in $\mathbb {R}^n$}{45}{section*.150}% 
\contentsline {paragraph}{Convex nondifferentiable optimization is hard}{45}{section*.151}% 
\contentsline {subsubsection}{Subgradient methods}{46}{section*.152}% 
\contentsline {paragraph}{Fundamental relationship}{46}{section*.153}% 
\contentsline {paragraph}{Deflected Subgradient}{46}{section*.154}% 
\contentsline {subsubsection}{Smoothed Gradient Methods}{47}{section*.155}% 
\contentsline {subsubsection}{Bundle Methods}{47}{section*.156}% 
\contentsline {paragraph}{Basic Idea}{47}{section*.157}% 
\contentsline {paragraph}{Cutting Plane Algorithm}{47}{section*.158}% 
\contentsline {subparagraph}{Why}{47}{section*.159}% 
\contentsline {subparagraph}{Stabilizing}{48}{section*.160}% 
\contentsline {section}{\numberline {2.3}Constrained Optimality and Duality}{48}{section.2.3}% 
\contentsline {paragraph}{Constrained Optimization}{48}{section*.161}% 
\contentsline {paragraph}{(Local) minima vs. optima}{48}{section*.162}% 
\contentsline {subsection}{\numberline {2.3.1}First-Order Optimality Conditions}{48}{subsection.2.3.1}% 
\contentsline {subsubsection}{Geometric Version}{48}{section*.163}% 
\contentsline {paragraph}{The Tangent Cone}{48}{section*.164}% 
\contentsline {paragraph}{Convex Sets}{49}{section*.165}% 
\contentsline {subsubsection}{Algebraic Version}{50}{section*.166}% 
\contentsline {paragraph}{Describing a Set via Functions}{50}{section*.167}% 
\contentsline {paragraph}{Convex Sets out of Convex Functions}{50}{section*.168}% 
\contentsline {paragraph}{Linear Equality Constraints}{50}{section*.169}% 
\contentsline {paragraph}{Nonlinear Inequalities}{51}{section*.170}% 
\contentsline {paragraph}{Farkas' Lemma}{51}{section*.171}% 
\contentsline {paragraph}{KKT Conditions}{51}{section*.172}% 
\contentsline {paragraph}{KKT Theorem}{51}{section*.173}% 
\contentsline {subsection}{\numberline {2.3.2}Second-Order Optimization}{51}{subsection.2.3.2}% 
\contentsline {paragraph}{Lagrangian Relaxation}{51}{section*.174}% 
\contentsline {paragraph}{Specialized Lagrangians}{52}{section*.175}% 
\contentsline {subsection}{\numberline {2.3.3}Constrained Optimization Algorithms}{52}{subsection.2.3.3}% 
\contentsline {subsubsection}{Quadratic Problem with Linear Equality Constraints}{53}{section*.176}% 
\contentsline {paragraph}{Equality-Constrained QP}{53}{section*.177}% 
\contentsline {paragraph}{Active-Set Method}{53}{section*.178}% 
\contentsline {subparagraph}{In practice}{54}{section*.179}% 
\contentsline {subsubsection}{Projected Gradient Method}{54}{section*.180}% 
\contentsline {paragraph}{Special Forms of Constraints}{54}{section*.181}% 
\contentsline {paragraph}{Goldstein's Version}{55}{section*.182}% 
\contentsline {paragraph}{Rosen's Version}{55}{section*.183}% 
\contentsline {subsubsection}{Frank-Wolfe Method}{56}{section*.184}% 
\contentsline {paragraph}{Stabilising the Frank-Wolfe Method}{56}{section*.185}% 
\contentsline {paragraph}{Constrained Cutting Plane (Bundle)}{56}{section*.186}% 
\contentsline {paragraph}{Frank-Wolfe++}{56}{section*.187}% 
\contentsline {subsubsection}{Dual Methods}{56}{section*.188}% 
\contentsline {paragraph}{Dual Method}{57}{section*.189}% 
\contentsline {subparagraph}{Decomposition}{57}{section*.190}% 
\contentsline {subsubsection}{Barrier Methods}{57}{section*.191}% 
\contentsline {paragraph}{Barrier Function and Central Path}{57}{section*.192}% 
\contentsline {paragraph}{Primal-Dual Interior-Point (Barrier) Method}{58}{section*.193}% 
