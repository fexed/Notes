\babel@toc {italian}{}\relax 
\babel@toc {italian}{}\relax 
\contentsline {section}{\numberline {0.1}Introduction}{2}{section.0.1}%
\contentsline {paragraph}{Objectives}{2}{section*.2}%
\contentsline {paragraph}{Methodology-Oriented Outcomes}{2}{section*.3}%
\contentsline {paragraph}{Application-Oriented Outcomes}{2}{section*.4}%
\contentsline {paragraph}{Prerequisites}{2}{section*.5}%
\contentsline {section}{\numberline {0.2}Pattern Recognition}{2}{section.0.2}%
\contentsline {paragraph}{Viola-Jones Algorithm}{2}{section*.6}%
\contentsline {paragraph}{An historical view}{2}{section*.7}%
\contentsline {paragraph}{A modern view}{2}{section*.8}%
\contentsline {paragraph}{The deep learning Lego}{2}{section*.9}%
\contentsline {subsection}{\numberline {0.2.1}Signals}{2}{subsection.0.2.1}%
\contentsline {paragraph}{Formalization}{2}{section*.10}%
\contentsline {paragraph}{Goals}{3}{section*.11}%
\contentsline {paragraph}{Key Methods}{3}{section*.12}%
\contentsline {subsubsection}{Time Domain Analysis}{3}{section*.13}%
\contentsline {paragraph}{Mean}{3}{section*.14}%
\contentsline {paragraph}{Autocovariance}{3}{section*.15}%
\contentsline {paragraph}{Autocorrelation}{3}{section*.16}%
\contentsline {subparagraph}{Autocorrelation plot}{3}{section*.17}%
\contentsline {paragraph}{Cross-Correlation}{3}{section*.18}%
\contentsline {subparagraph}{Normalized cross-correlation}{3}{section*.19}%
\contentsline {paragraph}{Autoregressive Process}{4}{section*.20}%
\contentsline {paragraph}{ARMA}{4}{section*.21}%
\contentsline {paragraph}{Estimating Autoregressive Models}{4}{section*.22}%
\contentsline {paragraph}{Comparing time series by AR}{4}{section*.23}%
\contentsline {subsubsection}{Spectral Domain Analysis}{4}{section*.24}%
\contentsline {paragraph}{Fourier Transform}{4}{section*.25}%
\contentsline {paragraph}{Representing functions}{5}{section*.26}%
\contentsline {paragraph}{Representing function in Complex space}{5}{section*.27}%
\contentsline {paragraph}{Representing Discrete Time Series}{5}{section*.28}%
\contentsline {paragraph}{Discrete Fourier Transform}{5}{section*.29}%
\contentsline {paragraph}{Basic Spectral Quantities in SFT}{5}{section*.30}%
\contentsline {paragraph}{DFT in Action}{5}{section*.31}%
\contentsline {subsection}{\numberline {0.2.2}Image Processing}{5}{subsection.0.2.2}%
\contentsline {subsubsection}{Descriptors}{5}{section*.32}%
\contentsline {paragraph}{Machine Vision Applications}{6}{section*.33}%
\contentsline {paragraph}{Key Questions}{6}{section*.34}%
\contentsline {paragraph}{Image Histograms}{6}{section*.35}%
\contentsline {paragraph}{Describing Local Image Properties}{6}{section*.36}%
\contentsline {paragraph}{Localized Descriptors}{6}{section*.37}%
\contentsline {paragraph}{SIFT}{6}{section*.38}%
\contentsline {subparagraph}{Gaussian Filter of an Image}{7}{section*.39}%
\contentsline {paragraph}{Fourier Analysis}{7}{section*.40}%
\contentsline {paragraph}{The Convolution Theorem}{7}{section*.41}%
\contentsline {subsubsection}{Detectors}{8}{section*.42}%
\contentsline {paragraph}{Visual Feature Detector}{8}{section*.43}%
\contentsline {paragraph}{Edge Detection}{8}{section*.44}%
\contentsline {subparagraph}{Edges and Gradients}{8}{section*.45}%
\contentsline {subparagraph}{Prewitt operators}{8}{section*.46}%
\contentsline {subparagraph}{Sobel Operator}{9}{section*.47}%
\contentsline {paragraph}{Blob Detection}{9}{section*.48}%
\contentsline {paragraph}{Affine Detectors}{9}{section*.49}%
\contentsline {paragraph}{MSER}{9}{section*.50}%
\contentsline {subparagraph}{Intuitions on MSER}{10}{section*.51}%
\contentsline {paragraph}{Image Segmentation}{10}{section*.52}%
\contentsline {subparagraph}{Ncut}{10}{section*.53}%
\contentsline {subsubsection}{Conclusion}{10}{section*.54}%
\contentsline {subsection}{\numberline {0.2.3}Wavelets}{10}{subsection.0.2.3}%
\contentsline {paragraph}{Limitations of DFT}{10}{section*.55}%
\contentsline {paragraph}{DWT}{11}{section*.56}%
\contentsline {section}{\numberline {0.3}Generative and Graphical Models}{11}{section.0.3}%
\contentsline {paragraph}{Generative Learning}{12}{section*.57}%
\contentsline {paragraph}{The Graphical Models Framework}{12}{section*.58}%
\contentsline {paragraph}{Representation}{12}{section*.59}%
\contentsline {paragraph}{In Deep Learning}{12}{section*.60}%
\contentsline {paragraph}{Generate new knowledge}{12}{section*.61}%
\contentsline {subsection}{\numberline {0.3.1}Probability Refresher}{12}{subsection.0.3.1}%
\contentsline {subsubsection}{Inference and Learning in Probabilistic Models}{13}{section*.62}%
\contentsline {paragraph}{Inference}{13}{section*.63}%
\contentsline {paragraph}{Learning}{13}{section*.64}%
\contentsline {paragraph}{Three Approaches to Inference}{13}{section*.65}%
\contentsline {paragraph}{Regularization}{13}{section*.66}%
\contentsline {paragraph}{Maximum-Likelihood Learning}{13}{section*.67}%
\contentsline {subsection}{\numberline {0.3.2}Graphical Models}{14}{subsection.0.3.2}%
\contentsline {subsubsection}{Bayesian Networks}{14}{section*.68}%
\contentsline {paragraph}{Conditional Probability Tables}{14}{section*.69}%
\contentsline {paragraph}{Plate notation}{14}{section*.70}%
\contentsline {paragraph}{Full-Plate Notation}{15}{section*.71}%
\contentsline {subsubsection}{Markov Random Fields}{15}{section*.72}%
\contentsline {subsection}{\numberline {0.3.3}Conditional Independence and Causality}{15}{subsection.0.3.3}%
\contentsline {paragraph}{Local Markov Property}{15}{section*.73}%
\contentsline {paragraph}{Markov Blanket}{15}{section*.74}%
\contentsline {paragraph}{Joint Probability Factorization}{16}{section*.75}%
\contentsline {paragraph}{Sampling of a Bayesian Network}{16}{section*.76}%
\contentsline {subsection}{\numberline {0.3.4}Fundamental Bayesian Network Structures}{16}{subsection.0.3.4}%
\contentsline {paragraph}{Tail to Tail}{16}{section*.77}%
\contentsline {paragraph}{Head to Tail}{16}{section*.78}%
\contentsline {paragraph}{Heat to Head}{16}{section*.79}%
\contentsline {paragraph}{Derived Conditional Independence Relationships}{17}{section*.80}%
\contentsline {paragraph}{$d$-separation}{17}{section*.81}%
\contentsline {paragraph}{Markov Blanket}{17}{section*.82}%
\contentsline {paragraph}{Are Directed Models Enough?}{17}{section*.83}%
\contentsline {subsection}{\numberline {0.3.5}Markov Random Fields}{17}{subsection.0.3.5}%
\contentsline {paragraph}{Joint Probability Factorization}{17}{section*.84}%
\contentsline {subparagraph}{Clique}{18}{section*.85}%
\contentsline {subparagraph}{Maximal Clique Factorization}{18}{section*.86}%
\contentsline {paragraph}{Potential Functions}{18}{section*.87}%
\contentsline {subparagraph}{Boltzmann Distribution}{18}{section*.88}%
\contentsline {subsubsection}{From Directed to Undirected}{18}{section*.89}%
\contentsline {subsection}{\numberline {0.3.6}Learning Causation from Data}{19}{subsection.0.3.6}%
\contentsline {paragraph}{Learning with Bayesian Network}{19}{section*.90}%
\contentsline {paragraph}{Structure Learning Problem}{19}{section*.91}%
\contentsline {subparagraph}{Structure Finding Approaches}{19}{section*.92}%
\contentsline {paragraph}{PC Algorithm}{20}{section*.93}%
\contentsline {subsection}{\numberline {0.3.7}Hidden Markov Models}{20}{subsection.0.3.7}%
\contentsline {paragraph}{Sequence}{20}{section*.94}%
\contentsline {paragraph}{Markov Chain}{20}{section*.95}%
\contentsline {subparagraph}{Example}{20}{section*.96}%
\contentsline {paragraph}{Observed Markov Chains}{20}{section*.97}%
\contentsline {paragraph}{Hidden Markov Models}{20}{section*.98}%
\contentsline {paragraph}{HMM Joint Probability Factorization}{21}{section*.99}%
\contentsline {paragraph}{HMMs as Recursive Models}{21}{section*.100}%
\contentsline {paragraph}{HMMs as Automata}{21}{section*.101}%
\contentsline {subsection}{\numberline {0.3.8}Notable Inference Problems}{21}{subsection.0.3.8}%
\contentsline {paragraph}{Smoothing}{21}{section*.102}%
\contentsline {paragraph}{Learning}{22}{section*.103}%
\contentsline {paragraph}{Optimal State Assigment}{22}{section*.104}%
\contentsline {subsubsection}{Forward-Backward Algorithm}{22}{section*.105}%
\contentsline {paragraph}{Sum-Product Message Passing}{23}{section*.106}%
\contentsline {subsubsection}{Learning in HMM}{23}{section*.107}%
\contentsline {paragraph}{Expectation-Maximization}{23}{section*.108}%
\contentsline {paragraph}{Expectation-Maximization Algorithm}{24}{section*.109}%
\contentsline {paragraph}{Usefulness of HMMs}{25}{section*.110}%
\contentsline {paragraph}{Decoding Problem}{25}{section*.111}%
\contentsline {subsubsection}{Viterbi Algorithm}{25}{section*.112}%
\contentsline {subsection}{\numberline {0.3.9}Input-output Hidden Markov Models}{26}{subsection.0.3.9}%
\contentsline {paragraph}{Bidirectional Input-Driven Models}{26}{section*.113}%
\contentsline {paragraph}{Coupled HMMs}{27}{section*.114}%
\contentsline {paragraph}{Dynamic Bayesian Networks}{27}{section*.115}%
\contentsline {subsection}{\numberline {0.3.10}Markov Random Fields}{27}{subsection.0.3.10}%
\contentsline {paragraph}{Likelihood Factorization}{27}{section*.116}%
\contentsline {paragraph}{Factor Graphs}{28}{section*.117}%
\contentsline {paragraph}{Sum-Product Inference}{28}{section*.118}%
\contentsline {paragraph}{Restricting to Conditional Probabilities}{28}{section*.119}%
\contentsline {subparagraph}{Conditional Random Field}{28}{section*.120}%
\contentsline {paragraph}{Feature Functions}{28}{section*.121}%
\contentsline {paragraph}{Discriminative Learning in Graphical Models}{29}{section*.122}%
\contentsline {paragraph}{CRF for Sequences}{29}{section*.123}%
\contentsline {paragraph}{Generalization of HMM}{29}{section*.124}%
\contentsline {paragraph}{Posterior Inference in LCRF}{29}{section*.125}%
\contentsline {paragraph}{Training LCRF}{30}{section*.126}%
\contentsline {paragraph}{Applications}{31}{section*.127}%
\contentsline {subsection}{\numberline {0.3.11}Bayesian Learning and Variational Inference}{31}{subsection.0.3.11}%
\contentsline {paragraph}{Latent Variables}{31}{section*.128}%
\contentsline {paragraph}{Latent Spaces}{31}{section*.129}%
\contentsline {paragraph}{Tractability}{31}{section*.130}%
\contentsline {subsubsection}{Kullback-Leibler Divergence}{31}{section*.131}%
\contentsline {paragraph}{Jensen Inequality}{32}{section*.132}%
\contentsline {paragraph}{Example}{32}{section*.133}%
\contentsline {paragraph}{Latent Dirichlet Allocation}{32}{section*.134}%
\contentsline {paragraph}{Dirichlet distribution}{33}{section*.135}%
\contentsline {paragraph}{LDA Generative Process}{33}{section*.136}%
\contentsline {subparagraph}{Learning}{34}{section*.137}%
\contentsline {paragraph}{Variational Inference}{34}{section*.138}%
\contentsline {paragraph}{Variational Expectation-Maximization}{34}{section*.139}%
\contentsline {subsection}{\numberline {0.3.12}Boltzmann Machines}{35}{subsection.0.3.12}%
\contentsline {paragraph}{Stochastic Binary Neurons}{35}{section*.140}%
\contentsline {paragraph}{Parallel Dynamics}{35}{section*.141}%
\contentsline {paragraph}{Glauber Dynamics}{36}{section*.142}%
\contentsline {subparagraph}{Boltzmann-Gibbs Distribution}{36}{section*.143}%
\contentsline {paragraph}{Learning}{36}{section*.144}%
\contentsline {paragraph}{Restricted Boltzmann Machines}{37}{section*.145}%
\contentsline {paragraph}{Contrastive-Divergence Learning}{38}{section*.146}%
\contentsline {subsection}{\numberline {0.3.13}Wrap Up}{38}{subsection.0.3.13}%
\contentsline {paragraph}{Tractability}{38}{section*.147}%
\contentsline {section}{\numberline {0.4}Sampling Methods}{39}{section.0.4}%
\contentsline {paragraph}{Sampling}{39}{section*.148}%
\contentsline {paragraph}{Sampling Procedure as Distributions}{39}{section*.149}%
\contentsline {subsection}{\numberline {0.4.1}Univariate Sampling}{40}{subsection.0.4.1}%
\contentsline {subsection}{\numberline {0.4.2}Multivariate Sampling}{40}{subsection.0.4.2}%
\contentsline {subparagraph}{Example}{40}{section*.150}%
\contentsline {paragraph}{Gibbs Sampling Procedure}{41}{section*.151}%
\contentsline {subparagraph}{$\hat {p}(X)$ of Gibbs sampling}{41}{section*.152}%
\contentsline {paragraph}{Markov Chain Monte Carlo Sampling Framework}{41}{section*.153}%
\contentsline {paragraph}{Procedures}{42}{section*.154}%
\contentsline {section}{\numberline {0.5}Convolutional Neural Networks}{42}{section.0.5}%
\contentsline {paragraph}{Deep Learning}{42}{section*.155}%
\contentsline {paragraph}{CNNs}{42}{section*.156}%
\contentsline {paragraph}{Dense Vector Multiplication}{42}{section*.157}%
\contentsline {paragraph}{Stride}{43}{section*.158}%
\contentsline {paragraph}{Activation Map Size}{43}{section*.159}%
\contentsline {paragraph}{Zero Padding}{43}{section*.160}%
\contentsline {paragraph}{Feature Map Transformation}{43}{section*.161}%
\contentsline {paragraph}{Pooling}{44}{section*.162}%
\contentsline {paragraph}{Convolutional Architecture}{44}{section*.163}%
\contentsline {paragraph}{Filter Banks}{45}{section*.164}%
\contentsline {paragraph}{Note on Convolution}{45}{section*.165}%
\contentsline {paragraph}{CNNs as Sparse Neural Networks}{45}{section*.166}%
\contentsline {subparagraph}{Strided Convolution}{45}{section*.167}%
\contentsline {subparagraph}{Pooling}{46}{section*.168}%
\contentsline {subparagraph}{Cross-Channel Pooling and Spatial Invariance}{46}{section*.169}%
\contentsline {subparagraph}{Hierarchical Feature Organization}{46}{section*.170}%
\contentsline {paragraph}{CNN Training}{46}{section*.171}%
\contentsline {paragraph}{Deconvolution}{47}{section*.172}%
\contentsline {paragraph}{ReLU}{47}{section*.173}%
\contentsline {paragraph}{VGGNet}{47}{section*.174}%
\contentsline {paragraph}{GoogLeNet}{47}{section*.175}%
\contentsline {paragraph}{Batch Normalization}{48}{section*.176}%
\contentsline {paragraph}{ResNet Trick}{48}{section*.177}%
\contentsline {paragraph}{Deconvolution Network}{48}{section*.178}%
\contentsline {paragraph}{Occlusions}{48}{section*.179}%
\contentsline {paragraph}{Dense CNN}{49}{section*.180}%
\contentsline {paragraph}{Causal Convolutions}{49}{section*.181}%
\contentsline {paragraph}{Fully Convolutional Networks}{49}{section*.182}%
\contentsline {paragraph}{Deconvolutional Architecture}{50}{section*.183}%
\contentsline {section}{\numberline {0.6}Autoencoders}{50}{section.0.6}%
\contentsline {paragraph}{Basic Autoencoder}{50}{section*.184}%
\contentsline {paragraph}{Neural Autoencoders}{50}{section*.185}%
\contentsline {subsection}{\numberline {0.6.1}Basic Autoencoders}{52}{subsection.0.6.1}%
\contentsline {paragraph}{Unsupervised Layerwise Pretraining}{52}{section*.186}%
\contentsline {paragraph}{Discriminative Fine Tuning}{53}{section*.187}%
\contentsline {paragraph}{Multimodal DBM}{53}{section*.188}%
\contentsline {section}{\numberline {0.7}Gated Recurrent Networks}{54}{section.0.7}%
\contentsline {paragraph}{RNN Design}{54}{section*.189}%
\contentsline {paragraph}{Supervised Recurrent Tasks}{54}{section*.190}%
\contentsline {paragraph}{Vanilla RNN}{55}{section*.191}%
\contentsline {paragraph}{Unfolding RNN}{55}{section*.192}%
\contentsline {paragraph}{Exploding/Vanishing Gradients}{55}{section*.193}%
\contentsline {paragraph}{Backward Propagation}{56}{section*.194}%
\contentsline {subparagraph}{Gradient Clipping for Exploding Gradients}{56}{section*.195}%
\contentsline {subparagraph}{Constant Error Propagation}{56}{section*.196}%
\contentsline {subparagraph}{Activation functions}{57}{section*.197}%
\contentsline {subparagraph}{Recurrent Weights}{57}{section*.198}%
\contentsline {paragraph}{Gating Units}{57}{section*.199}%
\contentsline {paragraph}{Forget Gate}{57}{section*.200}%
\contentsline {subsection}{\numberline {0.7.1}LSTM Cell}{58}{subsection.0.7.1}%
\contentsline {paragraph}{Long-Short Term Memory Cell}{58}{section*.201}%
\contentsline {paragraph}{LSTM in Equations}{59}{section*.202}%
\contentsline {paragraph}{Deep LSTM}{59}{section*.203}%
\contentsline {paragraph}{Training LSTM}{59}{section*.204}%
\contentsline {paragraph}{Regularizing LSTM}{59}{section*.205}%
\contentsline {paragraph}{Practicalities}{59}{section*.206}%
\contentsline {subsection}{\numberline {0.7.2}GRU Cell}{59}{subsection.0.7.2}%
\contentsline {paragraph}{Gated Recurrent Unit}{59}{section*.207}%
\contentsline {subsection}{\numberline {0.7.3}Applications}{60}{subsection.0.7.3}%
\contentsline {paragraph}{Bidirectional LSTM}{60}{section*.208}%
\contentsline {paragraph}{Language Modeling}{60}{section*.209}%
\contentsline {paragraph}{More Differentiable Compositions}{60}{section*.210}%
\contentsline {subsection}{\numberline {0.7.4}Advanced Topics}{61}{subsection.0.7.4}%
\contentsline {paragraph}{Language Modeling - Dynamic Evaluation}{61}{section*.211}%
\contentsline {paragraph}{Compression and Online Adaptation}{61}{section*.212}%
\contentsline {subsubsection}{Seq2Seq Models}{61}{section*.213}%
\contentsline {paragraph}{Sequence Transduction}{61}{section*.214}%
\contentsline {subsubsection}{Attention}{63}{section*.215}%
\contentsline {paragraph}{Generalized Relevance}{65}{section*.216}%
\contentsline {paragraph}{Hard Attention}{65}{section*.217}%
\contentsline {paragraph}{Transformers}{65}{section*.218}%
\contentsline {paragraph}{Self Attention}{65}{section*.219}%
\contentsline {subsubsection}{Hierarchical and Multiscale RNNs}{66}{section*.220}%
\contentsline {paragraph}{RNN and Memory}{66}{section*.221}%
\contentsline {paragraph}{Skipping State Updates}{66}{section*.222}%
\contentsline {paragraph}{Convolutional Seq2Seq}{66}{section*.223}%
\contentsline {paragraph}{Hierarchical RNNs}{66}{section*.224}%
\contentsline {paragraph}{Zoneout Regularization}{66}{section*.225}%
\contentsline {paragraph}{Clockwork RNN}{67}{section*.226}%
\contentsline {paragraph}{Skip RNN}{68}{section*.227}%
\contentsline {paragraph}{Hierarchical Sequential Structure}{68}{section*.228}%
\contentsline {paragraph}{Explicit Boundaries}{68}{section*.229}%
\contentsline {paragraph}{Hierarchical Multiscale RNN}{68}{section*.230}%
\contentsline {paragraph}{Recap}{68}{section*.231}%
\contentsline {section}{\numberline {0.8}Reservoir Computing}{69}{section.0.8}%
\contentsline {paragraph}{Fading and Exploding}{69}{section*.232}%
\contentsline {paragraph}{Reservoir Computing}{70}{section*.233}%
\contentsline {paragraph}{Architecture}{70}{section*.234}%
\contentsline {paragraph}{Setup}{70}{section*.235}%
\contentsline {paragraph}{Training}{70}{section*.236}%
\contentsline {paragraph}{Reservoir}{70}{section*.237}%
\contentsline {paragraph}{Echo State Property}{71}{section*.238}%
\contentsline {paragraph}{Initialization}{71}{section*.239}%
\contentsline {paragraph}{Dynamical Transient}{71}{section*.240}%
\contentsline {paragraph}{ESN Training}{71}{section*.241}%
\contentsline {section}{\numberline {0.9}Neural Reasoning}{71}{section.0.9}%
\contentsline {paragraph}{Memory Networks General Idea}{71}{section*.242}%
\contentsline {subsection}{\numberline {0.9.1}Memory Network}{72}{subsection.0.9.1}%
\contentsline {paragraph}{Components}{72}{section*.243}%
\contentsline {paragraph}{End-to-End Memory Networks}{72}{section*.244}%
\contentsline {paragraph}{Memory Nets for Visual Question Answering with Attention}{73}{section*.245}%
\contentsline {subsection}{\numberline {0.9.2}Neural Turing Machines}{73}{subsection.0.9.2}%
\contentsline {paragraph}{Controller}{73}{section*.246}%
\contentsline {paragraph}{Memory Read}{74}{section*.247}%
\contentsline {paragraph}{Memory Write}{74}{section*.248}%
\contentsline {paragraph}{NTM Attention Focusing}{74}{section*.249}%
\contentsline {section}{\numberline {0.10}Unsupervised Learning}{75}{section.0.10}%
\contentsline {paragraph}{The Problem}{75}{section*.250}%
\contentsline {paragraph}{Why Generative?}{75}{section*.251}%
\contentsline {paragraph}{Approaching the Problem from a DL Perspective}{75}{section*.252}%
\contentsline {paragraph}{Learning With Fully Visible Information}{76}{section*.253}%
\contentsline {paragraph}{NN With Latent Variables?}{76}{section*.254}%
\contentsline {subparagraph}{Reparametrization}{77}{section*.255}%
\contentsline {paragraph}{Variational Approximation}{78}{section*.256}%
\contentsline {subsection}{\numberline {0.10.1}Variational Autoencoder}{78}{subsection.0.10.1}%
\contentsline {paragraph}{Training}{78}{section*.257}%
\contentsline {paragraph}{VAE Final Loss}{78}{section*.258}%
\contentsline {subparagraph}{Information Theoretic Interpretation}{78}{section*.259}%
\contentsline {paragraph}{Testing}{79}{section*.260}%
\contentsline {paragraph}{VAE vs Denoising/Contractive AE}{79}{section*.261}%
\contentsline {paragraph}{Conditional Generation (CVAE)}{80}{section*.262}%
\contentsline {subsection}{\numberline {0.10.2}Implicit Models}{80}{subsection.0.10.2}%
\contentsline {paragraph}{Distribution Learning vs Learning to Sample}{80}{section*.263}%
\contentsline {paragraph}{The GAN Catch}{80}{section*.264}%
\contentsline {paragraph}{Hard Two-Player Game}{81}{section*.265}%
\contentsline {paragraph}{Wasserstein Distance Models}{81}{section*.266}%
\contentsline {paragraph}{DCGAN Architecture}{81}{section*.267}%
\contentsline {paragraph}{Progressive GAN}{81}{section*.268}%
\contentsline {paragraph}{Conditional Generation}{82}{section*.269}%
\contentsline {paragraph}{Best of two worlds}{82}{section*.270}%
\contentsline {paragraph}{Training AAE}{82}{section*.271}%
\contentsline {paragraph}{AAE Style Transfer}{83}{section*.272}%
\contentsline {paragraph}{AAE Semi-Supervised Learning}{83}{section*.273}%
\contentsline {paragraph}{Overview}{83}{section*.274}%
\contentsline {section}{\numberline {0.11}Continual Learning}{84}{section.0.11}%
\contentsline {paragraph}{Continual Learning}{84}{section*.275}%
\contentsline {paragraph}{Stability-plasticity dilemma}{84}{section*.276}%
\contentsline {paragraph}{}{84}{section*.277}%
\contentsline {paragraph}{Formally}{84}{section*.278}%
\contentsline {paragraph}{Benchmarks}{84}{section*.279}%
\contentsline {paragraph}{Scenarios}{84}{section*.280}%
\contentsline {paragraph}{Common Baselines}{85}{section*.281}%
\contentsline {paragraph}{Random Replay}{85}{section*.282}%
\contentsline {section}{\numberline {0.12}Reinforcement Learning}{85}{section.0.12}%
\contentsline {subsection}{\numberline {0.12.1}Fundamentals}{85}{subsection.0.12.1}%
\contentsline {paragraph}{Rewards}{85}{section*.283}%
\contentsline {paragraph}{Sequential Decision Making}{86}{section*.284}%
\contentsline {paragraph}{Agent and Environment}{86}{section*.285}%
\contentsline {paragraph}{History and State}{86}{section*.286}%
\contentsline {paragraph}{Environment State}{86}{section*.287}%
\contentsline {paragraph}{Agent State}{86}{section*.288}%
\contentsline {paragraph}{Information (Markov) State}{86}{section*.289}%
\contentsline {paragraph}{Observability}{86}{section*.290}%
\contentsline {subsection}{\numberline {0.12.2}Components}{87}{subsection.0.12.2}%
\contentsline {subparagraph}{Policy}{87}{section*.291}%
\contentsline {subparagraph}{Value Function}{87}{section*.292}%
\contentsline {subparagraph}{Model}{87}{section*.293}%
\contentsline {paragraph}{Characterizing RL Agents}{87}{section*.294}%
\contentsline {subsection}{\numberline {0.12.3}Problems}{87}{subsection.0.12.3}%
\contentsline {paragraph}{Learning vs Planning}{87}{section*.295}%
\contentsline {paragraph}{Exploration vs Exploitation}{87}{section*.296}%
\contentsline {paragraph}{Prediction vs Control}{87}{section*.297}%
\contentsline {paragraph}{Overview}{88}{section*.298}%
\contentsline {subsection}{\numberline {0.12.4}Markov Decision Processes}{88}{subsection.0.12.4}%
\contentsline {paragraph}{MDP}{88}{section*.299}%
\contentsline {subparagraph}{Value Function}{89}{section*.300}%
\contentsline {paragraph}{Bellman Equation for MDPs}{89}{section*.301}%
\contentsline {subparagraph}{Policy}{89}{section*.302}%
\contentsline {subparagraph}{Value Function with Policy}{89}{section*.303}%
\contentsline {paragraph}{Bellman Expectation Equation with Value and Action-Value function}{90}{section*.304}%
\contentsline {paragraph}{Optimal Value Function}{90}{section*.305}%
\contentsline {paragraph}{Optimal Policy}{91}{section*.306}%
\contentsline {subparagraph}{Theorem}{91}{section*.307}%
\contentsline {subparagraph}{Bellman Optimality Equations}{91}{section*.308}%
\contentsline {subsubsection}{MDP Extensions}{92}{section*.309}%
\contentsline {paragraph}{Infinite MDPs}{92}{section*.310}%
\contentsline {paragraph}{POMDP}{92}{section*.311}%
\contentsline {paragraph}{Belief State}{92}{section*.312}%
\contentsline {subsection}{\numberline {0.12.5}Model-Based Planning}{92}{subsection.0.12.5}%
\contentsline {paragraph}{Dynamic Programming}{92}{section*.313}%
\contentsline {paragraph}{Planning by Dynamic Programming}{92}{section*.314}%
\contentsline {paragraph}{Iterative Policy Evaluation}{93}{section*.315}%
\contentsline {paragraph}{Improving a Policy}{93}{section*.316}%
\contentsline {paragraph}{Formal Improvement}{93}{section*.317}%
\contentsline {subparagraph}{Modified Policy Improvement}{94}{section*.318}%
\contentsline {subsubsection}{Value Iteration}{94}{section*.319}%
\contentsline {paragraph}{Optimality Principle}{94}{section*.320}%
\contentsline {subparagraph}{Theorem}{94}{section*.321}%
\contentsline {paragraph}{Deterministic Value Iteration}{94}{section*.322}%
\contentsline {paragraph}{Value Iteration}{94}{section*.323}%
\contentsline {subsubsection}{Extensions}{94}{section*.324}%
\contentsline {subparagraph}{Asynchronous Backups}{94}{section*.325}%
\contentsline {paragraph}{Full-Width Backup}{95}{section*.326}%
\contentsline {paragraph}{Sample Backup}{95}{section*.327}%
\contentsline {subsection}{\numberline {0.12.6}Model-Free Reinforcement Learning}{95}{subsection.0.12.6}%
\contentsline {subsubsection}{Monte-Carlo Reinforcement Learning}{95}{section*.328}%
\contentsline {paragraph}{MC}{95}{section*.329}%
\contentsline {subparagraph}{MC Policy Evaluation}{95}{section*.330}%
\contentsline {subparagraph}{Incremental Mean MC Update}{96}{section*.331}%
\contentsline {subsubsection}{Temporal-Difference Learning}{96}{section*.332}%
\contentsline {paragraph}{MC vs TD}{96}{section*.333}%
\contentsline {paragraph}{Bias-Variance Tradeoff}{96}{section*.334}%
\contentsline {paragraph}{Batch MC and TD}{96}{section*.335}%
\contentsline {subparagraph}{Simple example}{97}{section*.336}%
\contentsline {paragraph}{Certainty Equivariance}{97}{section*.337}%
\contentsline {subsubsection}{Unifying and Generalizing}{97}{section*.338}%
\contentsline {paragraph}{MC Update}{97}{section*.339}%
\contentsline {paragraph}{Dynamic Programming}{98}{section*.340}%
\contentsline {paragraph}{TD Update}{98}{section*.341}%
\contentsline {paragraph}{$n$-step Prediction}{98}{section*.342}%
\contentsline {paragraph}{$\lambda $-returns (Forward View)}{99}{section*.343}%
\contentsline {paragraph}{Eligibility Traces}{99}{section*.344}%
\contentsline {paragraph}{Backward View TD($\lambda $)}{99}{section*.345}%
\contentsline {paragraph}{Model-Free RL: Control}{99}{section*.346}%
\contentsline {subsubsection}{On-Policy Learning}{100}{section*.347}%
\contentsline {paragraph}{Model-Free Policy Iteration Using Action-Value Function}{100}{section*.348}%
\contentsline {paragraph}{$\epsilon $-greedy Exploration}{100}{section*.349}%
\contentsline {paragraph}{Monte-Carlo Control}{100}{section*.350}%
\contentsline {paragraph}{On-Policy Control with SARSA}{100}{section*.351}%
\contentsline {subparagraph}{Updating Action-Value Functions with SARSA}{100}{section*.352}%
\contentsline {subsubsection}{Off-Policy Learning}{101}{section*.353}%
\contentsline {paragraph}{Q-Learning}{101}{section*.354}%
\contentsline {paragraph}{Off-Policy Control by Q-Learning}{101}{section*.355}%
\contentsline {subparagraph}{Theorem}{101}{section*.356}%
\contentsline {paragraph}{Wrap-Up}{101}{section*.357}%
\contentsline {subsection}{\numberline {0.12.7}Value-Function Approximation}{102}{subsection.0.12.7}%
\contentsline {subsubsection}{Incremental Methods}{102}{section*.358}%
\contentsline {paragraph}{Stochastic Gradient Descent}{102}{section*.359}%
\contentsline {paragraph}{Linear Value Function Approximation}{103}{section*.360}%
\contentsline {subparagraph}{Lookup Table and Features}{103}{section*.361}%
\contentsline {paragraph}{Incremental Prediction}{103}{section*.362}%
\contentsline {paragraph}{Value Function Approximation with MC}{103}{section*.363}%
\contentsline {paragraph}{Value Function Approximation with TD(0)}{103}{section*.364}%
\contentsline {paragraph}{Value Function Approximation with TD($\lambda $)}{104}{section*.365}%
\contentsline {paragraph}{Incremental Control}{104}{section*.366}%
\contentsline {paragraph}{Linear Action-Value Function Approximation}{104}{section*.367}%
\contentsline {paragraph}{Incremental Control Algorithms}{104}{section*.368}%
\contentsline {paragraph}{Baird's Counterexample}{105}{section*.369}%
\contentsline {paragraph}{Deadly Triad}{105}{section*.370}%
\contentsline {paragraph}{Convergence of Prediction Algorithms}{105}{section*.371}%
\contentsline {subsection}{\numberline {0.12.8}Batch Reinforcement Learning}{105}{subsection.0.12.8}%
\contentsline {paragraph}{SGD with Experience Replay}{105}{section*.372}%
\contentsline {paragraph}{Deep Q-Networks}{106}{section*.373}%
\contentsline {paragraph}{Atari-DQN}{106}{section*.374}%
\contentsline {paragraph}{Improvements on Original DQN}{106}{section*.375}%
\contentsline {subsection}{\numberline {0.12.9}Least Squares Prediction and Control}{106}{subsection.0.12.9}%
\contentsline {paragraph}{Linear Least Squares Prediction}{106}{section*.376}%
\contentsline {subparagraph}{Batch}{106}{section*.377}%
\contentsline {subparagraph}{Algorithms}{107}{section*.378}%
\contentsline {paragraph}{Linear Least Squares Control}{107}{section*.379}%
\contentsline {paragraph}{Linear Least Squares $Q$-learning}{107}{section*.380}%
\contentsline {subsection}{\numberline {0.12.10}Policy-Based Reinforcement Learning}{108}{subsection.0.12.10}%
\contentsline {paragraph}{Advantages}{108}{section*.381}%
\contentsline {paragraph}{Disadvantages}{108}{section*.382}%
\contentsline {subparagraph}{Example}{108}{section*.383}%
\contentsline {subsubsection}{Policy Gradient}{108}{section*.384}%
\contentsline {paragraph}{Policy Objective Functions}{108}{section*.385}%
\contentsline {paragraph}{Policy Gradient}{108}{section*.386}%
\contentsline {subparagraph}{Theorem}{108}{section*.387}%
\contentsline {paragraph}{Score Function}{109}{section*.388}%
\contentsline {subparagraph}{Softmax Policy}{109}{section*.389}%
\contentsline {subparagraph}{Gaussian Policy}{109}{section*.390}%
\contentsline {paragraph}{Reinforce: MC Policy Gradient}{109}{section*.391}%
\contentsline {subparagraph}{Evaluate the MC Policy Gradient}{109}{section*.392}%
\contentsline {subsubsection}{Actor Critic}{110}{section*.393}%
\contentsline {paragraph}{Estimating the Action-Value Function}{110}{section*.394}%
\contentsline {paragraph}{Action-Value Actor-Critic}{110}{section*.395}%
\contentsline {paragraph}{Bias in Actor-Critic Algorithms}{110}{section*.396}%
\contentsline {paragraph}{Reducing Variance Using a Baseline}{110}{section*.397}%
\contentsline {paragraph}{Estimating the Advantage Function}{111}{section*.398}%
\contentsline {subsubsection}{Natural Policy Gradient}{111}{section*.399}%
\contentsline {paragraph}{Alternative Policy Gradient Directions}{111}{section*.400}%
\contentsline {paragraph}{Covariant/Natural Policy Gradient}{111}{section*.401}%
\contentsline {paragraph}{Trust Region Policy Optimization}{111}{section*.402}%
\contentsline {paragraph}{Proximal Policy Optimization}{112}{section*.403}%
\contentsline {subsubsection}{Deep Policy Networks}{112}{section*.404}%
\contentsline {paragraph}{Policy Gradients}{112}{section*.405}%
\contentsline {paragraph}{Actor-Critic Algorithm}{112}{section*.406}%
\contentsline {paragraph}{A3C}{112}{section*.407}%
\contentsline {paragraph}{Deep Reinforcement Learning with Continuous Actions}{113}{section*.408}%
\contentsline {paragraph}{Deep Deterministic Policy Gradients}{113}{section*.409}%
\contentsline {subsection}{\numberline {0.12.11}Model-Based Reinforcement Learning}{113}{subsection.0.12.11}%
\contentsline {paragraph}{Advantages}{113}{section*.410}%
\contentsline {paragraph}{Disadvantages}{113}{section*.411}%
\contentsline {subsubsection}{Model}{113}{section*.412}%
\contentsline {paragraph}{Model Learning}{114}{section*.413}%
\contentsline {subparagraph}{Model Learning with Table Lookup}{114}{section*.414}%
\contentsline {subparagraph}{Example}{114}{section*.415}%
\contentsline {paragraph}{Planning with a Model}{114}{section*.416}%
\contentsline {paragraph}{Sample-Based Planning}{114}{section*.417}%
\contentsline {subparagraph}{Example}{115}{section*.418}%
\contentsline {paragraph}{Planning with an Inaccurate Model}{115}{section*.419}%
\contentsline {subsubsection}{Integrated Architecture}{115}{section*.420}%
\contentsline {paragraph}{Real and Simulated Experience}{115}{section*.421}%
\contentsline {paragraph}{Integrating Learning and Planning}{115}{section*.422}%
\contentsline {subsubsection}{Learning with Simulation}{116}{section*.423}%
\contentsline {paragraph}{Forward Search}{116}{section*.424}%
\contentsline {paragraph}{Simulation-Based Search}{116}{section*.425}%
\contentsline {paragraph}{MCTS}{116}{section*.426}%
\contentsline {subparagraph}{MCTS: Evaluate}{116}{section*.427}%
\contentsline {subparagraph}{MCTS: Simulate}{117}{section*.428}%
\contentsline {subparagraph}{Advantages of MCTS}{117}{section*.429}%
\contentsline {paragraph}{MC vs TD Search}{117}{section*.430}%
\contentsline {paragraph}{Temporal-Difference Search}{117}{section*.431}%
\contentsline {subsection}{\numberline {0.12.12}Three Types of Reinforcement Learning}{118}{subsection.0.12.12}%
\contentsline {paragraph}{Value-Based}{118}{section*.432}%
\contentsline {paragraph}{Policy-Based}{118}{section*.433}%
\contentsline {paragraph}{Model-Based}{118}{section*.434}%
\contentsline {subsection}{\numberline {0.12.13}Alpha-Go}{118}{subsection.0.12.13}%
\contentsline {paragraph}{Go}{118}{section*.435}%
\contentsline {subparagraph}{Position Evaluation}{118}{section*.436}%
\contentsline {subparagraph}{Monte-Carlo Evaluation}{118}{section*.437}%
\contentsline {paragraph}{Alpha-Go}{119}{section*.438}%
\contentsline {paragraph}{Supervised-Reinforcement Learning Pipeline}{119}{section*.439}%
\contentsline {subparagraph}{Offline Phase}{119}{section*.440}%
\contentsline {subparagraph}{Simulation Phase}{119}{section*.441}%
\contentsline {section}{\numberline {0.13}Deep Graph Networks}{121}{section.0.13}%
\contentsline {paragraph}{Graph Structured Data}{121}{section*.442}%
\contentsline {paragraph}{Deep Learning with Graphs}{121}{section*.443}%
\contentsline {paragraph}{Predictive Tasks}{121}{section*.444}%
\contentsline {paragraph}{Trasductive Tasks}{121}{section*.445}%
\contentsline {paragraph}{Contractive Approach}{122}{section*.446}%
\contentsline {paragraph}{Contextual Approach}{122}{section*.447}%
\contentsline {paragraph}{Deep Graph Networks}{122}{section*.448}%
\contentsline {subsection}{\numberline {0.13.1}CNNs for Graphs}{122}{subsection.0.13.1}%
\contentsline {paragraph}{Spatial Domain}{122}{section*.449}%
\contentsline {paragraph}{Spectral Domain}{122}{section*.450}%
\contentsline {subparagraph}{Spectral Scenario}{122}{section*.451}%
\contentsline {subparagraph}{Spectral Graph Convolution in 1 Slide}{122}{section*.452}%
\contentsline {paragraph}{Graph View on Image Convolutions}{122}{section*.453}%
\contentsline {paragraph}{Node Neighborhoods}{123}{section*.454}%
\contentsline {subsection}{\numberline {0.13.2}Contractive Graph Processing}{123}{subsection.0.13.2}%
\contentsline {paragraph}{Graph Embedding by Learning-Free Neurons}{123}{section*.455}%
\contentsline {subsection}{\numberline {0.13.3}Contextual Graph Processing}{123}{subsection.0.13.3}%
\contentsline {paragraph}{Neighborhood Aggregation and Layering}{123}{section*.456}%
\contentsline {paragraph}{Graph Convolutional Layer}{124}{section*.457}%
\contentsline {paragraph}{Graph Isomorphism Network}{124}{section*.458}%
\contentsline {paragraph}{Graph Attention}{124}{section*.459}%
\contentsline {paragraph}{Using Node Embedding}{124}{section*.460}%
\contentsline {paragraph}{Training the Embedding}{124}{section*.461}%
\contentsline {subsection}{\numberline {0.13.4}Unsupervised Structure Embeddings}{125}{subsection.0.13.4}%
\contentsline {paragraph}{Generative Learning for Graphs}{125}{section*.462}%
\contentsline {paragraph}{CGMM}{125}{section*.463}%
\contentsline {paragraph}{Incremental Construction}{125}{section*.464}%
\contentsline {paragraph}{CGMM Layer Training}{125}{section*.465}%
\contentsline {paragraph}{CGMM}{125}{section*.466}%
\contentsline {paragraph}{Interpreting CGMM}{125}{section*.467}%
\contentsline {paragraph}{•}{126}{section*.468}%
\contentsline {paragraph}{ICGMM}{126}{section*.469}%
\contentsline {subsection}{\numberline {0.13.5}Advanced Topics}{126}{subsection.0.13.5}%
\contentsline {paragraph}{Pooling}{126}{section*.470}%
\contentsline {paragraph}{Graph Theoretical Approaches}{126}{section*.471}%
\contentsline {paragraph}{Graph Variational Autoencoders}{126}{section*.472}%
\contentsline {paragraph}{Language-Based Graph Generation}{126}{section*.473}%
\contentsline {paragraph}{Explaining Deep Graph Networks}{126}{section*.474}%
\contentsline {paragraph}{Modern View on Pattern Recognition}{126}{section*.475}%
\contentsline {paragraph}{Convergence of Neural-Generative Paradigms}{126}{section*.476}%
