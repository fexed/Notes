\babel@toc {italian}{}
\babel@toc {italian}{}
\contentsline {section}{\numberline {0.1}Introduction}{2}{section.0.1}% 
\contentsline {paragraph}{Objectives}{2}{section*.2}% 
\contentsline {paragraph}{Methodology-Oriented Outcomes}{2}{section*.3}% 
\contentsline {paragraph}{Application-Oriented Outcomes}{2}{section*.4}% 
\contentsline {paragraph}{Prerequisites}{2}{section*.5}% 
\contentsline {section}{\numberline {0.2}Pattern Recognition}{2}{section.0.2}% 
\contentsline {paragraph}{Origins}{2}{section*.6}% 
\contentsline {paragraph}{Viola-Jones Algorithm}{2}{section*.7}% 
\contentsline {paragraph}{An historical view}{2}{section*.8}% 
\contentsline {paragraph}{A modern view}{2}{section*.9}% 
\contentsline {paragraph}{The deep learning Lego}{2}{section*.10}% 
\contentsline {subsection}{\numberline {0.2.1}Signals}{2}{subsection.0.2.1}% 
\contentsline {paragraph}{Formalization}{2}{section*.11}% 
\contentsline {paragraph}{Goals}{3}{section*.12}% 
\contentsline {paragraph}{Key Methods}{3}{section*.13}% 
\contentsline {subsubsection}{Time Domain Analysis}{3}{section*.14}% 
\contentsline {paragraph}{Mean}{3}{section*.15}% 
\contentsline {paragraph}{Autocovariance}{3}{section*.16}% 
\contentsline {paragraph}{Autocorrelation}{3}{section*.17}% 
\contentsline {subparagraph}{Autocorrelation plot}{3}{section*.18}% 
\contentsline {paragraph}{Cross-Correlation}{3}{section*.19}% 
\contentsline {subparagraph}{Normalized cross-correlation}{3}{section*.20}% 
\contentsline {paragraph}{Autoregressive Process}{4}{section*.21}% 
\contentsline {paragraph}{ARMA}{4}{section*.22}% 
\contentsline {paragraph}{Estimating Autoregressive Models}{4}{section*.23}% 
\contentsline {paragraph}{Comparing time series by AR}{4}{section*.24}% 
\contentsline {subsubsection}{Spectral Domain Analysis}{4}{section*.25}% 
\contentsline {paragraph}{Fourier Transform}{4}{section*.26}% 
\contentsline {paragraph}{Representing functions}{5}{section*.27}% 
\contentsline {paragraph}{Representing function in Complex space}{5}{section*.28}% 
\contentsline {paragraph}{Representing Discrete Time Series}{5}{section*.29}% 
\contentsline {paragraph}{Discrete Fourier Transform}{5}{section*.30}% 
\contentsline {paragraph}{Basic Spectral Quantities in SFT}{5}{section*.31}% 
\contentsline {paragraph}{DFT in Action}{5}{section*.32}% 
\contentsline {subsection}{\numberline {0.2.2}Image Processing}{5}{subsection.0.2.2}% 
\contentsline {subsubsection}{Descriptors}{5}{section*.33}% 
\contentsline {paragraph}{Machine Vision Applications}{6}{section*.34}% 
\contentsline {paragraph}{Key Questions}{6}{section*.35}% 
\contentsline {paragraph}{Image Histograms}{6}{section*.36}% 
\contentsline {paragraph}{Describing Local Image Properties}{6}{section*.37}% 
\contentsline {paragraph}{Localized Descriptors}{6}{section*.38}% 
\contentsline {paragraph}{SIFT}{6}{section*.39}% 
\contentsline {subparagraph}{Gaussian Filter of an Image}{7}{section*.40}% 
\contentsline {paragraph}{Fourier Analysis}{7}{section*.41}% 
\contentsline {paragraph}{The Convolution Theorem}{7}{section*.42}% 
\contentsline {subsubsection}{Detectors}{8}{section*.43}% 
\contentsline {paragraph}{Visual Feature Detector}{8}{section*.44}% 
\contentsline {paragraph}{Edge Detection}{8}{section*.45}% 
\contentsline {subparagraph}{Edges and Gradients}{8}{section*.46}% 
\contentsline {subparagraph}{Prewitt operators}{8}{section*.47}% 
\contentsline {subparagraph}{Sobel Operator}{9}{section*.48}% 
\contentsline {paragraph}{Blob Detection}{9}{section*.49}% 
\contentsline {paragraph}{Affine Detectors}{9}{section*.50}% 
\contentsline {paragraph}{MSER}{9}{section*.51}% 
\contentsline {subparagraph}{Intuitions on MSER}{10}{section*.52}% 
\contentsline {paragraph}{Image Segmentation}{10}{section*.53}% 
\contentsline {subparagraph}{Ncut}{10}{section*.54}% 
\contentsline {subsubsection}{Conclusion}{10}{section*.55}% 
\contentsline {subsection}{\numberline {0.2.3}Wavelets}{10}{subsection.0.2.3}% 
\contentsline {paragraph}{Limitations of DFT}{10}{section*.56}% 
\contentsline {paragraph}{DWT}{11}{section*.57}% 
\contentsline {section}{\numberline {0.3}Generative and Graphical Models}{11}{section.0.3}% 
\contentsline {paragraph}{Generative Learning}{11}{section*.58}% 
\contentsline {paragraph}{The Graphical Models Framework}{12}{section*.59}% 
\contentsline {paragraph}{Representation}{12}{section*.60}% 
\contentsline {paragraph}{In Deep Learning}{12}{section*.61}% 
\contentsline {paragraph}{Generate new knowledge}{12}{section*.62}% 
\contentsline {subsection}{\numberline {0.3.1}Probability Refresher}{12}{subsection.0.3.1}% 
\contentsline {subsubsection}{Inference and Learning in Probabilistic Models}{12}{section*.63}% 
\contentsline {paragraph}{Inference}{12}{section*.64}% 
\contentsline {paragraph}{Learning}{13}{section*.65}% 
\contentsline {paragraph}{Three Approaches}{13}{section*.66}% 
\contentsline {paragraph}{Regularization}{13}{section*.67}% 
\contentsline {paragraph}{Maximum-Likelihood Learning}{13}{section*.68}% 
\contentsline {subsection}{\numberline {0.3.2}Graphical Models}{14}{subsection.0.3.2}% 
\contentsline {subsubsection}{Bayesian Networks}{14}{section*.69}% 
\contentsline {paragraph}{Conditional Probability Tables}{14}{section*.70}% 
\contentsline {paragraph}{Plate notation}{14}{section*.71}% 
\contentsline {paragraph}{Full-Plate Notation}{14}{section*.72}% 
\contentsline {subsubsection}{Markov Random Fields}{15}{section*.73}% 
\contentsline {subsection}{\numberline {0.3.3}Conditional Independence and Causality}{15}{subsection.0.3.3}% 
\contentsline {paragraph}{Local Markov Property}{15}{section*.74}% 
\contentsline {paragraph}{Markov Blanket}{15}{section*.75}% 
\contentsline {paragraph}{Joint Probability Factorization}{15}{section*.76}% 
\contentsline {paragraph}{Sampling of a Bayesian Network}{16}{section*.77}% 
\contentsline {subsection}{\numberline {0.3.4}Fundamental Bayesian Network Structures}{16}{subsection.0.3.4}% 
\contentsline {paragraph}{Tail to Tail}{16}{section*.78}% 
\contentsline {paragraph}{Head to Tail}{16}{section*.79}% 
\contentsline {paragraph}{Heat to Head}{16}{section*.80}% 
\contentsline {paragraph}{Derived Conditional Independence Relationships}{16}{section*.81}% 
\contentsline {paragraph}{$d$-separation}{17}{section*.82}% 
\contentsline {paragraph}{Markov Blanket}{17}{section*.83}% 
\contentsline {paragraph}{Are Directed Models Enough?}{17}{section*.84}% 
\contentsline {subsection}{\numberline {0.3.5}Markov Random Fields}{17}{subsection.0.3.5}% 
\contentsline {paragraph}{Joint Probability Factorization}{17}{section*.85}% 
\contentsline {subparagraph}{Clique}{17}{section*.86}% 
\contentsline {subparagraph}{Maximal Clique Factorization}{18}{section*.87}% 
\contentsline {paragraph}{Potential Functions}{18}{section*.88}% 
\contentsline {paragraph}{Boltzmann Distribution}{18}{section*.89}% 
\contentsline {subsubsection}{From Directed to Undirected}{18}{section*.90}% 
\contentsline {subsection}{\numberline {0.3.6}Learning Causation from Data}{18}{subsection.0.3.6}% 
\contentsline {paragraph}{Learning with Bayesian Network}{18}{section*.91}% 
\contentsline {paragraph}{Structure Learning Problem}{19}{section*.92}% 
\contentsline {subparagraph}{Structure Finding Approaches}{19}{section*.93}% 
\contentsline {paragraph}{PC Algorithm}{20}{section*.94}% 
\contentsline {subsection}{\numberline {0.3.7}Hidden Markov Models}{20}{subsection.0.3.7}% 
\contentsline {paragraph}{Sequence}{20}{section*.95}% 
\contentsline {paragraph}{Markov Chain}{20}{section*.96}% 
\contentsline {paragraph}{Observed Markov Chains}{20}{section*.97}% 
\contentsline {paragraph}{Hidden Markov Models}{20}{section*.98}% 
\contentsline {paragraph}{HMM Joint Probability Factorization}{21}{section*.99}% 
\contentsline {paragraph}{HMMs as Recursive Models}{21}{section*.100}% 
\contentsline {paragraph}{HMMs as Automata}{21}{section*.101}% 
\contentsline {subsection}{\numberline {0.3.8}Notable Inference Problems}{22}{subsection.0.3.8}% 
\contentsline {paragraph}{Smoothing}{22}{section*.102}% 
\contentsline {paragraph}{Learning}{22}{section*.103}% 
\contentsline {paragraph}{Optimal State Assigment}{22}{section*.104}% 
\contentsline {subsubsection}{Forward-Backward Algorithm}{22}{section*.105}% 
\contentsline {paragraph}{Sum-Product Message Passing}{23}{section*.106}% 
\contentsline {subsubsection}{Learning in HMM}{23}{section*.107}% 
\contentsline {paragraph}{Expectation-Maximization}{23}{section*.108}% 
\contentsline {paragraph}{Expectation-Maximization Algorithm}{24}{section*.109}% 
\contentsline {paragraph}{Usefulness of HMMs}{25}{section*.110}% 
\contentsline {paragraph}{Decoding Problem}{25}{section*.111}% 
\contentsline {subsubsection}{Viterbi Algorithm}{25}{section*.112}% 
\contentsline {subsection}{\numberline {0.3.9}Input-output Hidden Markov Models}{26}{subsection.0.3.9}% 
\contentsline {paragraph}{Bidirectional Input-Driven Models}{26}{section*.113}% 
\contentsline {paragraph}{Coupled HMMs}{26}{section*.114}% 
\contentsline {paragraph}{Dynamic Bayesian Networks}{26}{section*.115}% 
\contentsline {subsection}{\numberline {0.3.10}Markov Random Fields}{27}{subsection.0.3.10}% 
\contentsline {paragraph}{Likelihood Factorization}{27}{section*.116}% 
\contentsline {paragraph}{Factor Graphs}{27}{section*.117}% 
\contentsline {paragraph}{Sum-Product Inference}{27}{section*.118}% 
\contentsline {paragraph}{Restricting to Conditional Probabilities}{28}{section*.119}% 
\contentsline {subparagraph}{Conditional Random Field}{28}{section*.120}% 
\contentsline {paragraph}{Feature Functions}{28}{section*.121}% 
\contentsline {paragraph}{Discriminative Learning in Graphical Models}{28}{section*.122}% 
\contentsline {paragraph}{CRF for Sequences}{28}{section*.123}% 
\contentsline {paragraph}{Generalization of HMM}{29}{section*.124}% 
\contentsline {paragraph}{Posterior Inference in LCRF}{29}{section*.125}% 
\contentsline {paragraph}{Training LCRF}{29}{section*.126}% 
\contentsline {paragraph}{Applications}{30}{section*.127}% 
\contentsline {subsection}{\numberline {0.3.11}Bayesian Learning and Variational Inference}{30}{subsection.0.3.11}% 
\contentsline {paragraph}{Latent Variables}{31}{section*.128}% 
\contentsline {paragraph}{Latent Spaces}{31}{section*.129}% 
\contentsline {paragraph}{Tractability}{31}{section*.130}% 
\contentsline {subsubsection}{Kullback-Leibler Divergence}{31}{section*.131}% 
\contentsline {paragraph}{Jensen Inequality}{31}{section*.132}% 
\contentsline {paragraph}{Example}{32}{section*.133}% 
\contentsline {paragraph}{Latent Dirichlet Allocation}{32}{section*.134}% 
\contentsline {paragraph}{Dirichlet distribution}{33}{section*.135}% 
\contentsline {paragraph}{LDA Generative Process}{33}{section*.136}% 
\contentsline {subparagraph}{Learning}{33}{section*.137}% 
\contentsline {paragraph}{Variational Inference}{34}{section*.138}% 
\contentsline {paragraph}{Variational Expectation-Maximization}{34}{section*.139}% 
\contentsline {subsection}{\numberline {0.3.12}Boltzmann Machines}{34}{subsection.0.3.12}% 
\contentsline {paragraph}{Stochastic Binary Neurons}{35}{section*.140}% 
\contentsline {paragraph}{Parallel Dynamics}{35}{section*.141}% 
\contentsline {paragraph}{Glauber Dynamics}{35}{section*.142}% 
\contentsline {subparagraph}{Boltzmann-Gibbs Distribution}{35}{section*.143}% 
\contentsline {paragraph}{Learning}{35}{section*.144}% 
\contentsline {paragraph}{Restricted Boltzmann Machines}{36}{section*.145}% 
\contentsline {paragraph}{Contrastive-Divergence Learning}{37}{section*.146}% 
\contentsline {subsection}{\numberline {0.3.13}Wrap Up}{38}{subsection.0.3.13}% 
\contentsline {paragraph}{Tractability}{38}{section*.147}% 
\contentsline {section}{\numberline {0.4}Sampling Methods}{38}{section.0.4}% 
\contentsline {paragraph}{Sampling}{38}{section*.148}% 
\contentsline {paragraph}{Sampling Procedure as Distributions}{38}{section*.149}% 
\contentsline {subsection}{\numberline {0.4.1}Univariate Sampling}{40}{subsection.0.4.1}% 
\contentsline {subsection}{\numberline {0.4.2}Multivariate Sampling}{40}{subsection.0.4.2}% 
\contentsline {subparagraph}{Example}{40}{section*.150}% 
\contentsline {paragraph}{Gibbs Sampling Procedure}{41}{section*.151}% 
\contentsline {subparagraph}{$\mathaccentV {hat}05E{p}(X)$ of Gibbs sampling}{41}{section*.152}% 
\contentsline {paragraph}{Markov Chain Monte Carlo Sampling Framework}{41}{section*.153}% 
\contentsline {paragraph}{Procedures}{42}{section*.154}% 
\contentsline {section}{\numberline {0.5}Convolutional Neural Networks}{42}{section.0.5}% 
\contentsline {paragraph}{Deep Learning}{42}{section*.155}% 
\contentsline {paragraph}{CNNs}{42}{section*.156}% 
\contentsline {paragraph}{Dense Vector Multiplication}{42}{section*.157}% 
\contentsline {paragraph}{Stride}{43}{section*.158}% 
\contentsline {paragraph}{Activation Map Size}{43}{section*.159}% 
\contentsline {paragraph}{Zero Padding}{43}{section*.160}% 
\contentsline {paragraph}{Feature Map Transformation}{43}{section*.161}% 
\contentsline {paragraph}{Pooling}{44}{section*.162}% 
\contentsline {paragraph}{Convolutional Architecture}{44}{section*.163}% 
\contentsline {paragraph}{Filter Banks}{45}{section*.164}% 
\contentsline {paragraph}{Note on Convolution}{45}{section*.165}% 
\contentsline {paragraph}{CNNs as Sparse Neural Networks}{45}{section*.166}% 
\contentsline {subparagraph}{Strided Convolution}{45}{section*.167}% 
\contentsline {subparagraph}{Pooling}{46}{section*.168}% 
\contentsline {subparagraph}{Cross-Channel Pooling and Spatial Invariance}{46}{section*.169}% 
\contentsline {subparagraph}{Hierarchical Feature Organization}{46}{section*.170}% 
\contentsline {paragraph}{CNN Training}{46}{section*.171}% 
\contentsline {paragraph}{Deconvolution}{47}{section*.172}% 
\contentsline {paragraph}{ReLU}{47}{section*.173}% 
\contentsline {paragraph}{VGGNet}{47}{section*.174}% 
\contentsline {paragraph}{GoogLeNet}{47}{section*.175}% 
\contentsline {paragraph}{Batch Normalization}{48}{section*.176}% 
\contentsline {paragraph}{Deconvolution Network}{48}{section*.177}% 
\contentsline {paragraph}{Occlusions}{48}{section*.178}% 
\contentsline {paragraph}{Dense CNN}{48}{section*.179}% 
\contentsline {paragraph}{Causal Convolutions}{48}{section*.180}% 
\contentsline {paragraph}{Fully Convolutional Networks}{49}{section*.181}% 
\contentsline {paragraph}{Deconvolutional Architecture}{49}{section*.182}% 
\contentsline {section}{\numberline {0.6}Autoencoders}{49}{section.0.6}% 
\contentsline {paragraph}{Basic Autoencoder}{49}{section*.183}% 
\contentsline {paragraph}{Neural Autoencoders}{50}{section*.184}% 
\contentsline {subparagraph}{Sparse Autoencoder}{50}{section*.185}% 
\contentsline {subparagraph}{Denoising Autoencoders}{50}{section*.186}% 
\contentsline {subparagraph}{Contractive Autoencoder}{51}{section*.187}% 
\contentsline {subsection}{\numberline {0.6.1}Basic Autoencoders}{51}{subsection.0.6.1}% 
\contentsline {paragraph}{Unsupervised Layerwise Pretraining}{51}{section*.188}% 
\contentsline {paragraph}{Discriminative Fine Tuning}{53}{section*.189}% 
\contentsline {paragraph}{Multimodal DBM}{53}{section*.190}% 
\contentsline {section}{\numberline {0.7}Gated Recurrent Networks}{53}{section.0.7}% 
\contentsline {paragraph}{RNN Design}{53}{section*.191}% 
\contentsline {paragraph}{Supervised Recurrent Tasks}{54}{section*.192}% 
\contentsline {paragraph}{Vanilla RNN}{54}{section*.193}% 
\contentsline {paragraph}{Unfolding RNN}{54}{section*.194}% 
\contentsline {paragraph}{Exploding/Vanishing Gradients}{55}{section*.195}% 
\contentsline {paragraph}{Backward Propagation}{55}{section*.196}% 
\contentsline {subparagraph}{Gradient Clipping for Exploding Gradients}{56}{section*.197}% 
\contentsline {subparagraph}{Constant Error Propagation}{56}{section*.198}% 
\contentsline {subparagraph}{Activation functions}{56}{section*.199}% 
\contentsline {subparagraph}{Recurrent Weights}{56}{section*.200}% 
\contentsline {paragraph}{Gating Units}{56}{section*.201}% 
\contentsline {paragraph}{Forget Gate}{56}{section*.202}% 
\contentsline {subsection}{\numberline {0.7.1}LSTM Cell}{57}{subsection.0.7.1}% 
\contentsline {paragraph}{Long-Short Term Memory Cell}{57}{section*.203}% 
\contentsline {paragraph}{LSTM in Equations}{58}{section*.204}% 
\contentsline {paragraph}{Deep LSTM}{58}{section*.205}% 
\contentsline {paragraph}{Training LSTM}{58}{section*.206}% 
\contentsline {paragraph}{Regularizing LSTM}{58}{section*.207}% 
\contentsline {paragraph}{Practicalities}{58}{section*.208}% 
\contentsline {subsection}{\numberline {0.7.2}GRU Cell}{59}{subsection.0.7.2}% 
\contentsline {paragraph}{Gated Recurrent Unit}{59}{section*.209}% 
\contentsline {subsection}{\numberline {0.7.3}Applications}{59}{subsection.0.7.3}% 
\contentsline {paragraph}{Bidirectional LSTM}{59}{section*.210}% 
\contentsline {paragraph}{Language Modeling}{59}{section*.211}% 
\contentsline {paragraph}{More Differentiable Compositions}{60}{section*.212}% 
\contentsline {subsection}{\numberline {0.7.4}Advanced Topics}{60}{subsection.0.7.4}% 
\contentsline {paragraph}{Language Modeling - Dynamic Evaluation}{60}{section*.213}% 
\contentsline {paragraph}{Compression and Online Adaptation}{60}{section*.214}% 
\contentsline {subsubsection}{Seq2Seq Models}{60}{section*.215}% 
\contentsline {paragraph}{Sequence Transduction}{61}{section*.216}% 
\contentsline {paragraph}{Attention}{62}{section*.217}% 
\contentsline {paragraph}{Generalized Relevance}{63}{section*.218}% 
\contentsline {paragraph}{Hard Attention}{64}{section*.219}% 
\contentsline {paragraph}{Transformers}{64}{section*.220}% 
\contentsline {paragraph}{Self Attention}{64}{section*.221}% 
\contentsline {subsection}{\numberline {0.7.5}Skipping State Updates}{65}{subsection.0.7.5}% 
\contentsline {paragraph}{Convolutional Seq2Seq}{65}{section*.222}% 
\contentsline {paragraph}{Hierarchical RNNs}{65}{section*.223}% 
\contentsline {subparagraph}{Zoneout Regularization}{65}{section*.224}% 
\contentsline {paragraph}{Clockwork RNN}{66}{section*.225}% 
\contentsline {paragraph}{Skip RNN}{66}{section*.226}% 
\contentsline {subsection}{\numberline {0.7.6}Hierarchical Networks}{67}{subsection.0.7.6}% 
\contentsline {paragraph}{Explicit Boundaries}{67}{section*.227}% 
\contentsline {paragraph}{Operations}{67}{section*.228}% 
\contentsline {paragraph}{Recap}{67}{section*.229}% 
\contentsline {section}{\numberline {0.8}Reservoir Computing}{67}{section.0.8}% 
\contentsline {paragraph}{Reservoir Computing}{68}{section*.230}% 
\contentsline {paragraph}{Architecture}{69}{section*.231}% 
\contentsline {paragraph}{Setup}{69}{section*.232}% 
\contentsline {paragraph}{Training}{69}{section*.233}% 
\contentsline {paragraph}{Reservoir}{69}{section*.234}% 
\contentsline {paragraph}{Echo State Property}{69}{section*.235}% 
\contentsline {paragraph}{Initialization}{69}{section*.236}% 
\contentsline {paragraph}{Dynamical Transient}{69}{section*.237}% 
\contentsline {paragraph}{ESN Training}{70}{section*.238}% 
\contentsline {section}{\numberline {0.9}Neural Reasoning}{70}{section.0.9}% 
\contentsline {paragraph}{Memory Networks General Idea}{70}{section*.239}% 
\contentsline {subsection}{\numberline {0.9.1}Memory Network}{70}{subsection.0.9.1}% 
\contentsline {paragraph}{Components}{70}{section*.240}% 
\contentsline {paragraph}{End-to-End Memory Networks}{71}{section*.241}% 
\contentsline {paragraph}{Memory Nets for Visual Question Answering with Attention}{71}{section*.242}% 
\contentsline {subsection}{\numberline {0.9.2}Neural Turing Machines}{72}{subsection.0.9.2}% 
\contentsline {paragraph}{Controller}{72}{section*.243}% 
\contentsline {paragraph}{Memory Read}{72}{section*.244}% 
\contentsline {paragraph}{Memory Write}{72}{section*.245}% 
\contentsline {paragraph}{NTM Attention Focusing}{73}{section*.246}% 
\contentsline {section}{\numberline {0.10}Unsupervised Learning}{74}{section.0.10}% 
\contentsline {paragraph}{The Problem}{74}{section*.247}% 
\contentsline {paragraph}{Why Generative?}{74}{section*.248}% 
\contentsline {paragraph}{Approaching the Problem from a DL Perspective}{74}{section*.249}% 
\contentsline {paragraph}{Learning With Fully Visible Information}{74}{section*.250}% 
\contentsline {paragraph}{NN With Latent Variables?}{75}{section*.251}% 
\contentsline {subparagraph}{Reparametrization}{76}{section*.252}% 
\contentsline {paragraph}{Variational Approximation}{76}{section*.253}% 
\contentsline {subsection}{\numberline {0.10.1}Variational Autoencoder}{76}{subsection.0.10.1}% 
\contentsline {paragraph}{Training}{77}{section*.254}% 
\contentsline {paragraph}{VAE Final Loss}{77}{section*.255}% 
\contentsline {subparagraph}{Information Theoretic Interpretation}{77}{section*.256}% 
\contentsline {paragraph}{Testing}{77}{section*.257}% 
\contentsline {paragraph}{VAE vs Denoising/Contractive AE}{77}{section*.258}% 
\contentsline {paragraph}{Conditional Generation (CVAE)}{77}{section*.259}% 
\contentsline {subsection}{\numberline {0.10.2}Implicit Models}{78}{subsection.0.10.2}% 
\contentsline {paragraph}{Distribution Learning vs Learning to Sample}{78}{section*.260}% 
\contentsline {paragraph}{The GAN Catch}{78}{section*.261}% 
\contentsline {paragraph}{Hard Two-Player Game}{79}{section*.262}% 
\contentsline {paragraph}{Wasserstein Distance Models}{79}{section*.263}% 
\contentsline {paragraph}{DCGAN Architecture}{79}{section*.264}% 
\contentsline {paragraph}{Progressive GAN}{79}{section*.265}% 
\contentsline {paragraph}{Conditional Generation}{80}{section*.266}% 
\contentsline {paragraph}{Best of two worlds}{80}{section*.267}% 
\contentsline {paragraph}{Training AAE}{80}{section*.268}% 
\contentsline {paragraph}{AAE Style Transfer}{80}{section*.269}% 
\contentsline {paragraph}{AAE Semi-Supervised Learning}{81}{section*.270}% 
\contentsline {paragraph}{Overview}{81}{section*.271}% 
\contentsline {section}{\numberline {0.11}Continual Learning}{81}{section.0.11}% 
\contentsline {paragraph}{Continual Learning}{81}{section*.272}% 
\contentsline {paragraph}{Stability-plasticity dilemma}{81}{section*.273}% 
\contentsline {paragraph}{}{82}{section*.274}% 
\contentsline {paragraph}{Formally}{82}{section*.275}% 
\contentsline {paragraph}{Benchmarks}{82}{section*.276}% 
\contentsline {paragraph}{Scenarios}{82}{section*.277}% 
\contentsline {paragraph}{Common Baselines}{82}{section*.278}% 
\contentsline {paragraph}{Random Replay}{82}{section*.279}% 
\contentsline {section}{\numberline {0.12}Reinforcement Learning}{82}{section.0.12}% 
\contentsline {subsection}{\numberline {0.12.1}Fundamentals}{83}{subsection.0.12.1}% 
\contentsline {paragraph}{Rewards}{83}{section*.280}% 
\contentsline {paragraph}{Sequential Decision Making}{83}{section*.281}% 
\contentsline {paragraph}{Agent and Environment}{83}{section*.282}% 
\contentsline {paragraph}{History and State}{83}{section*.283}% 
\contentsline {paragraph}{Environment State}{83}{section*.284}% 
\contentsline {paragraph}{Agent State}{83}{section*.285}% 
\contentsline {paragraph}{Information (Markov) State}{84}{section*.286}% 
\contentsline {paragraph}{Observability}{84}{section*.287}% 
\contentsline {subsection}{\numberline {0.12.2}Components}{84}{subsection.0.12.2}% 
\contentsline {subparagraph}{Policy}{84}{section*.288}% 
\contentsline {subparagraph}{Value Function}{84}{section*.289}% 
\contentsline {subparagraph}{Model}{84}{section*.290}% 
\contentsline {paragraph}{Characterizing RL Agents}{84}{section*.291}% 
\contentsline {subsection}{\numberline {0.12.3}Problems}{85}{subsection.0.12.3}% 
\contentsline {paragraph}{Learning vs Planning}{85}{section*.292}% 
\contentsline {paragraph}{Exploration vs Exploitation}{85}{section*.293}% 
\contentsline {paragraph}{Prediction vs Control}{85}{section*.294}% 
\contentsline {paragraph}{Overview}{85}{section*.295}% 
\contentsline {paragraph}{MDP}{85}{section*.296}% 
\contentsline {subparagraph}{Value Function}{86}{section*.297}% 
\contentsline {paragraph}{Bellman Equation for MDPs}{86}{section*.298}% 
\contentsline {subparagraph}{Policy}{86}{section*.299}% 
\contentsline {subparagraph}{Value Function with Policy}{86}{section*.300}% 
\contentsline {paragraph}{Bellman Expectation Equation with Value and Action-Value function}{87}{section*.301}% 
\contentsline {paragraph}{Optimal Value Function}{88}{section*.302}% 
\contentsline {paragraph}{Optimal Policy}{88}{section*.303}% 
\contentsline {subparagraph}{Theorem}{88}{section*.304}% 
\contentsline {subparagraph}{Bellman Optimality Equations}{89}{section*.305}% 
\contentsline {subsection}{\numberline {0.12.4}Model-Based Planning}{89}{subsection.0.12.4}% 
\contentsline {paragraph}{Dynamic Programming}{89}{section*.306}% 
\contentsline {paragraph}{Planning by Dynamic Programming}{89}{section*.307}% 
\contentsline {paragraph}{Iterative Policy Evaluation}{89}{section*.308}% 
\contentsline {paragraph}{Improving a Policy}{89}{section*.309}% 
\contentsline {paragraph}{Formal Improvement}{90}{section*.310}% 
\contentsline {subparagraph}{Modified Policy Improvement}{90}{section*.311}% 
\contentsline {paragraph}{Optimality Principle}{90}{section*.312}% 
\contentsline {subparagraph}{Theorem}{90}{section*.313}% 
\contentsline {paragraph}{Deterministic Value Iteration}{90}{section*.314}% 
\contentsline {paragraph}{Value Iteration}{91}{section*.315}% 
\contentsline {subsubsection}{Extensions}{91}{section*.316}% 
\contentsline {subparagraph}{Asynchronous Backups}{91}{section*.317}% 
\contentsline {paragraph}{Full-Width Backup}{91}{section*.318}% 
\contentsline {paragraph}{Sample Backup}{91}{section*.319}% 
\contentsline {subsection}{\numberline {0.12.5}Model-Free Reinforcement Learning}{92}{subsection.0.12.5}% 
\contentsline {subsubsection}{Monte-Carlo Reinforcement Learning}{92}{section*.320}% 
\contentsline {paragraph}{MC}{92}{section*.321}% 
\contentsline {subparagraph}{MC Policy Evaluation}{92}{section*.322}% 
\contentsline {subparagraph}{Incremental Mean MC Update}{92}{section*.323}% 
\contentsline {subsubsection}{Temporal-Difference Learning}{92}{section*.324}% 
\contentsline {paragraph}{MC vs TD}{92}{section*.325}% 
\contentsline {paragraph}{Bias-Variance Tradeoff}{93}{section*.326}% 
\contentsline {paragraph}{Batch MC and TD}{93}{section*.327}% 
\contentsline {subparagraph}{Simple example}{93}{section*.328}% 
\contentsline {paragraph}{Certainty Equivalence}{93}{section*.329}% 
\contentsline {subsubsection}{Unifying and Generalizing}{94}{section*.330}% 
\contentsline {paragraph}{MC Update}{94}{section*.331}% 
\contentsline {paragraph}{Dynamic Programming}{94}{section*.332}% 
\contentsline {paragraph}{TD Update}{94}{section*.333}% 
\contentsline {paragraph}{$n$-step Prediction}{94}{section*.334}% 
\contentsline {paragraph}{$\lambda $-returns (Forward View)}{95}{section*.335}% 
\contentsline {paragraph}{Eligibility Traces}{95}{section*.336}% 
\contentsline {paragraph}{Backward View TD($\lambda $)}{96}{section*.337}% 
\contentsline {subsubsection}{On-Policy Learning}{96}{section*.338}% 
\contentsline {paragraph}{Model-Free Policy Iteration Using Action-Value Function}{96}{section*.339}% 
\contentsline {paragraph}{$\epsilon $-greedy Exploration}{96}{section*.340}% 
\contentsline {paragraph}{Monte-Carlo Control}{96}{section*.341}% 
\contentsline {paragraph}{On-Policy Control with SARSA}{96}{section*.342}% 
\contentsline {subparagraph}{Updating Action-Value Functions with SARSA}{97}{section*.343}% 
\contentsline {subsubsection}{Off-Policy Learning}{97}{section*.344}% 
\contentsline {paragraph}{Q-Learning}{97}{section*.345}% 
\contentsline {paragraph}{Off-Policy Control by Q-Learning}{97}{section*.346}% 
\contentsline {subparagraph}{Theorem}{97}{section*.347}% 
\contentsline {paragraph}{Wrap-Up}{97}{section*.348}% 
\contentsline {subsection}{\numberline {0.12.6}Value-Function Approximation}{98}{subsection.0.12.6}% 
\contentsline {subsubsection}{Incremental Methods}{99}{section*.349}% 
\contentsline {paragraph}{Stochastic Gradient Descent}{99}{section*.350}% 
\contentsline {paragraph}{Linear Value Function Approximation}{99}{section*.351}% 
\contentsline {subparagraph}{Lookup Table and Features}{99}{section*.352}% 
\contentsline {subsubsection}{Incremental Prediction}{100}{section*.353}% 
\contentsline {paragraph}{Value Function Approximation with MC}{100}{section*.354}% 
\contentsline {paragraph}{Value Function Approximation with TD(0)}{100}{section*.355}% 
\contentsline {paragraph}{Value Function Approximation with TD($\lambda $)}{100}{section*.356}% 
\contentsline {subsubsection}{Incremental Control}{100}{section*.357}% 
\contentsline {paragraph}{Linear Action-Value Function Approximation}{101}{section*.358}% 
\contentsline {paragraph}{Incremental Control Algorithms}{101}{section*.359}% 
\contentsline {paragraph}{Baird's Counterexample}{101}{section*.360}% 
\contentsline {paragraph}{Deadly Triad}{101}{section*.361}% 
\contentsline {paragraph}{Convergence of Prediction Algorithms}{102}{section*.362}% 
\contentsline {subsection}{\numberline {0.12.7}Batch Reinforcement Learning}{102}{subsection.0.12.7}% 
\contentsline {paragraph}{SGD with Experience Replay}{102}{section*.363}% 
\contentsline {paragraph}{Deep Q-Networks}{102}{section*.364}% 
\contentsline {paragraph}{Atari-DQN}{102}{section*.365}% 
\contentsline {paragraph}{Improvements on Original DQN}{103}{section*.366}% 
\contentsline {subsection}{\numberline {0.12.8}Least Squares Prediction and Control}{103}{subsection.0.12.8}% 
\contentsline {paragraph}{Linear Least Squares Prediction}{103}{section*.367}% 
\contentsline {subparagraph}{Batch}{103}{section*.368}% 
\contentsline {subparagraph}{Algorithms}{103}{section*.369}% 
\contentsline {paragraph}{Linear Least Squares Control}{103}{section*.370}% 
\contentsline {paragraph}{Linear Least Squares $Q$-learning}{104}{section*.371}% 
\contentsline {subsection}{\numberline {0.12.9}Policy-Based Reinforcement Learning}{104}{subsection.0.12.9}% 
\contentsline {paragraph}{Advantages}{104}{section*.372}% 
\contentsline {paragraph}{Disadvantages}{104}{section*.373}% 
\contentsline {subparagraph}{Example}{104}{section*.374}% 
\contentsline {subsubsection}{Policy Gradient}{105}{section*.375}% 
\contentsline {paragraph}{Policy Objective Functions}{105}{section*.376}% 
\contentsline {paragraph}{Policy Gradient}{105}{section*.377}% 
\contentsline {subparagraph}{Theorem}{105}{section*.378}% 
\contentsline {paragraph}{Score Function}{105}{section*.379}% 
\contentsline {subparagraph}{Softmax Policy}{105}{section*.380}% 
\contentsline {subparagraph}{Gaussian Policy}{105}{section*.381}% 
\contentsline {paragraph}{Reinforce: MC Policy Gradient}{105}{section*.382}% 
\contentsline {subparagraph}{Evaluate the MC Policy Gradient}{106}{section*.383}% 
\contentsline {subsubsection}{Actor Critic}{106}{section*.384}% 
\contentsline {paragraph}{Estimating the Action-Value Function}{106}{section*.385}% 
\contentsline {paragraph}{Action-Value Actor-Critic}{107}{section*.386}% 
\contentsline {paragraph}{Bias in Actor-Critic Algorithms}{107}{section*.387}% 
\contentsline {paragraph}{Reducing Variance Using a Baseline}{107}{section*.388}% 
\contentsline {paragraph}{Estimating the Advantage Function}{107}{section*.389}% 
\contentsline {subsubsection}{Natural Policy Gradient}{108}{section*.390}% 
\contentsline {paragraph}{Alternative Policy Gradient Directions}{108}{section*.391}% 
\contentsline {paragraph}{Covariant/Natural Policy Gradient}{108}{section*.392}% 
\contentsline {paragraph}{Trust Region Policy Optimization}{108}{section*.393}% 
\contentsline {paragraph}{Proximal Policy Optimization}{108}{section*.394}% 
\contentsline {subsubsection}{Deep Policy Networks}{108}{section*.395}% 
\contentsline {paragraph}{Policy Gradients}{108}{section*.396}% 
\contentsline {paragraph}{Actor-Critic Algorithm}{109}{section*.397}% 
\contentsline {paragraph}{A3C}{109}{section*.398}% 
\contentsline {paragraph}{Deep Reinforcement Learning with Continuous Actions}{109}{section*.399}% 
\contentsline {paragraph}{Deep Deterministic Policy Gradients}{109}{section*.400}% 
\contentsline {subsection}{\numberline {0.12.10}Model-Based Reinforcement Learning}{109}{subsection.0.12.10}% 
\contentsline {paragraph}{Advantages}{110}{section*.401}% 
\contentsline {paragraph}{Disadvantages}{110}{section*.402}% 
\contentsline {subsubsection}{Model}{110}{section*.403}% 
\contentsline {paragraph}{Model Learning}{110}{section*.404}% 
\contentsline {subparagraph}{Model Learning with Table Lookup}{110}{section*.405}% 
\contentsline {subparagraph}{Example}{111}{section*.406}% 
\contentsline {paragraph}{Planning with a Model}{111}{section*.407}% 
\contentsline {paragraph}{Sample-Based Planning}{111}{section*.408}% 
\contentsline {subparagraph}{Example}{111}{section*.409}% 
\contentsline {paragraph}{Planning with an Inaccurate Model}{111}{section*.410}% 
\contentsline {subsubsection}{Integrated Architecture}{112}{section*.411}% 
\contentsline {paragraph}{Real and Simulated Experience}{112}{section*.412}% 
\contentsline {paragraph}{Integrating Learning and Planning}{112}{section*.413}% 
\contentsline {subsubsection}{Learning with Simulation}{112}{section*.414}% 
\contentsline {paragraph}{Forward Search}{112}{section*.415}% 
\contentsline {paragraph}{Simulation-Based Search}{113}{section*.416}% 
\contentsline {paragraph}{MCTS}{113}{section*.417}% 
\contentsline {subparagraph}{MCTS: Evaluate}{113}{section*.418}% 
\contentsline {subparagraph}{MCTS: Simulate}{113}{section*.419}% 
\contentsline {subparagraph}{Advantages of MCTS}{114}{section*.420}% 
\contentsline {paragraph}{MC vs TD Search}{114}{section*.421}% 
\contentsline {paragraph}{Temporal-Difference Search}{114}{section*.422}% 
\contentsline {subsection}{\numberline {0.12.11}Three Types of Reinforcement Learning}{114}{subsection.0.12.11}% 
\contentsline {paragraph}{Value-Based}{114}{section*.423}% 
\contentsline {paragraph}{Policy-Based}{114}{section*.424}% 
\contentsline {paragraph}{Model-Based}{114}{section*.425}% 
\contentsline {subsection}{\numberline {0.12.12}Alpha-Go}{115}{subsection.0.12.12}% 
\contentsline {paragraph}{Go}{115}{section*.426}% 
\contentsline {subparagraph}{Position Evaluation}{115}{section*.427}% 
\contentsline {subparagraph}{Monte-Carlo Evaluation}{115}{section*.428}% 
\contentsline {paragraph}{Alpha-Go}{115}{section*.429}% 
\contentsline {paragraph}{Supervised-Reinforcement Learning Pipeline}{116}{section*.430}% 
\contentsline {subparagraph}{Offline Phase}{116}{section*.431}% 
\contentsline {subparagraph}{Simulation Phase}{116}{section*.432}% 
\contentsline {section}{\numberline {0.13}Deep Graph Networks}{117}{section.0.13}% 
\contentsline {paragraph}{Graph Structured Data}{117}{section*.433}% 
\contentsline {paragraph}{Deep Learning with Graphs}{117}{section*.434}% 
\contentsline {paragraph}{Predictive Tasks}{117}{section*.435}% 
\contentsline {paragraph}{Trasductive Tasks}{117}{section*.436}% 
\contentsline {paragraph}{Contractive Approach}{118}{section*.437}% 
\contentsline {paragraph}{Contextual Approach}{118}{section*.438}% 
\contentsline {paragraph}{Deep Graph Networks}{118}{section*.439}% 
\contentsline {subsection}{\numberline {0.13.1}CNNs for Graphs}{118}{subsection.0.13.1}% 
\contentsline {paragraph}{Spatial Domain}{118}{section*.440}% 
\contentsline {paragraph}{Spectral Domain}{118}{section*.441}% 
\contentsline {subparagraph}{Spectral Scenario}{118}{section*.442}% 
\contentsline {subparagraph}{Spectral Graph Convolution in 1 Slide}{118}{section*.443}% 
\contentsline {paragraph}{Graph View on Image Convolutions}{118}{section*.444}% 
\contentsline {paragraph}{Node Neighborhoods}{119}{section*.445}% 
\contentsline {subsection}{\numberline {0.13.2}Contractive Graph Processing}{119}{subsection.0.13.2}% 
\contentsline {paragraph}{Graph Embedding by Learning-Free Neurons}{119}{section*.446}% 
\contentsline {subsection}{\numberline {0.13.3}Contextual Graph Processing}{119}{subsection.0.13.3}% 
\contentsline {paragraph}{Neighborhood Aggregation and Layering}{119}{section*.447}% 
\contentsline {paragraph}{Graph Convolutional Layer}{120}{section*.448}% 
\contentsline {paragraph}{Graph Isomorphism Network}{120}{section*.449}% 
\contentsline {paragraph}{Graph Attention}{120}{section*.450}% 
\contentsline {paragraph}{Using Node Embedding}{120}{section*.451}% 
\contentsline {paragraph}{Training the Embedding}{120}{section*.452}% 
\contentsline {subsection}{\numberline {0.13.4}Unsupervised Structure Embeddings}{121}{subsection.0.13.4}% 
\contentsline {paragraph}{Generative Learning for Graphs}{121}{section*.453}% 
\contentsline {paragraph}{CGMM}{121}{section*.454}% 
\contentsline {paragraph}{Incremental Construction}{121}{section*.455}% 
\contentsline {paragraph}{CGMM Layer Training}{121}{section*.456}% 
\contentsline {paragraph}{CGMM}{121}{section*.457}% 
\contentsline {paragraph}{Interpreting CGMM}{121}{section*.458}% 
\contentsline {paragraph}{\IeC {\textbullet }}{122}{section*.459}% 
\contentsline {paragraph}{ICGMM}{122}{section*.460}% 
\contentsline {subsection}{\numberline {0.13.5}Advanced Topics}{122}{subsection.0.13.5}% 
\contentsline {paragraph}{Pooling}{122}{section*.461}% 
\contentsline {paragraph}{Graph Theoretical Approaches}{122}{section*.462}% 
\contentsline {paragraph}{Graph Variational Autoencoders}{122}{section*.463}% 
\contentsline {paragraph}{Language-Based Graph Generation}{122}{section*.464}% 
\contentsline {paragraph}{Explaining Deep Graph Networks}{122}{section*.465}% 
\contentsline {paragraph}{Modern View on Pattern Recognition}{122}{section*.466}% 
\contentsline {paragraph}{Convergence of Neural-Generative Paradigms}{122}{section*.467}% 
