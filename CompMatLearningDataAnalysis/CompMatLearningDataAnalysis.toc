\babel@toc {italian}{}
\babel@toc {italian}{}
\contentsline {section}{\numberline {0.1}Introduction}{2}{section.0.1}% 
\contentsline {chapter}{\numberline {1}Numerical Analysis}{3}{chapter.1}% 
\contentsline {paragraph}{Quick recap of linear algebra}{3}{section*.2}% 
\contentsline {paragraph}{}{4}{section*.3}% 
\contentsline {paragraph}{Norms}{4}{section*.4}% 
\contentsline {paragraph}{Orthogonal}{4}{section*.5}% 
\contentsline {paragraph}{Eigenvalues and eigenvectors}{4}{section*.6}% 
\contentsline {paragraph}{Symmetry}{4}{section*.7}% 
\contentsline {paragraph}{Spectral Theorem}{4}{section*.8}% 
\contentsline {paragraph}{Quadratic form}{4}{section*.9}% 
\contentsline {paragraph}{Positive Semidefinite}{4}{section*.10}% 
\contentsline {paragraph}{Recall theorem}{5}{section*.11}% 
\contentsline {paragraph}{Generalization for complex matrices}{5}{section*.12}% 
\contentsline {paragraph}{Singular Value Decomposition}{5}{section*.13}% 
\contentsline {paragraph}{Eckart-Young Theorem}{5}{section*.14}% 
\contentsline {paragraph}{Ranks}{5}{section*.15}% 
\contentsline {paragraph}{SVD Approximation}{5}{section*.16}% 
\contentsline {subparagraph}{Best approximations}{6}{section*.17}% 
\contentsline {paragraph}{Linear Least Squares problems}{6}{section*.18}% 
\contentsline {paragraph}{Polynomial Fitting}{6}{section*.19}% 
\contentsline {paragraph}{Theory of least-squares problems}{6}{section*.20}% 
\contentsline {subparagraph}{Theorem}{6}{section*.21}% 
\contentsline {subparagraph}{Algorithm}{7}{section*.22}% 
\contentsline {paragraph}{Pseudoinverse}{7}{section*.23}% 
\contentsline {paragraph}{QR factorization of a matrix}{7}{section*.24}% 
\contentsline {subparagraph}{Numerical problems}{8}{section*.25}% 
\contentsline {paragraph}{Theorem}{8}{section*.26}% 
\contentsline {paragraph}{Effect of noise in data}{10}{section*.27}% 
\contentsline {paragraph}{Tikhonov Regularization/Ridge Regression}{10}{section*.28}% 
\contentsline {chapter}{\numberline {2}Optimization}{11}{chapter.2}% 
\contentsline {paragraph}{Optimality conditions}{11}{section*.29}% 
\contentsline {paragraph}{Optimization need to be approximate}{11}{section*.30}% 
\contentsline {paragraph}{Optimization at least possible}{11}{section*.31}% 
\contentsline {paragraph}{Local Optimization}{11}{section*.32}% 
\contentsline {paragraph}{Optimally choosing the iterates}{11}{section*.33}% 
\contentsline {paragraph}{To make it go faster, give it more information}{12}{section*.34}% 
\contentsline {paragraph}{Dichotomic Search}{12}{section*.35}% 
\contentsline {paragraph}{Extreme value theorem}{13}{section*.36}% 
\contentsline {paragraph}{Fastest local optimization}{13}{section*.37}% 
\contentsline {paragraph}{Measuring algorithms speed}{13}{section*.38}% 
\contentsline {paragraph}{Improving dichotomic search}{13}{section*.39}% 
\contentsline {paragraph}{Newton's method}{13}{section*.40}% 
\contentsline {paragraph}{Global optimization}{14}{section*.41}% 
\contentsline {paragraph}{Convexity}{14}{section*.42}% 
\contentsline {paragraph}{Multivariate}{14}{section*.43}% 
\contentsline {subparagraph}{Unconstraint global optimization}{14}{section*.44}% 
\contentsline {paragraph}{Tomography}{14}{section*.45}% 
\contentsline {paragraph}{Simple Functions}{14}{section*.46}% 
