\documentclass[10pt]{book}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage{multicol}
\usepackage[bookmarks]{hyperref}
\usepackage[a4paper, total={18cm, 25cm}]{geometry}
\usepackage{color}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\usepackage{listings}
\lstset{
	language=Python,
	commentstyle=\color{mygray},
	morekeywords={function, returns, static, persistent}
}
\usepackage{graphicx}
\usepackage{makecell}
\graphicspath{ {./img/} }
\usepackage{color}

\begin{document}
\renewcommand*\contentsname{Indice}
\title{Introduzione all'Intelligenza Artificiale}
\author{Federico Matteoni}
\date{A.A. 2019/20}
\maketitle
\tableofcontents
\pagebreak
\section*{Introduzione}
Alessio Micheli, Maria Simi\\
\texttt{elearning.di.unipi.it/course/view.php?id=174}\\
Intelligenza Artificiale si occupa della \textbf{comprensione} e della \textbf{riproduzione} del comportamento \textit{intelligente}.\\
Psicologia cognitiva: obiettivo comprensione intelligenza umana, costruendo modelli computazionali e verifica sperimentale.\\
Approccio costruttivo: costruire entità dotate di intelligenze e \textbf{razionalità}. Questo tramite codifica del pensiero razionale per risolvere problemi che richiedono intelligenza non necessariamente facendolo come lo fa l'uomo.\\
Definizioni di IA: pensiero-azione, umanamente-razionalmente.\\
Costruire macchine intelligenti sia che operino come l'uomo che diversamente.\\
formalizzaz conoscenze e meccanizzazione ragionemtno in tutti i settori dell'uomo\\
comprensione tramite modelli comp della psicologia e comportamente di uomini, animali ecc\\
rendere il lavoro con il calcolatore altrettanto facile e utile che del lavoro con persone capaci, abili e disponibili.\\\\
Poniamo definizione di IA: arte di creare macchine che svolgono funzioni che richiedono intelligenza quando svolte da esseri umani. Non definisce "Intelligenza", cosa significa "intelligente"?\\

\chapter{Agenti Intelligenti}
\section{Intelligenza}
L'intelligenza è vista come l'avere diverse capacità, durante il progresso nell'area di ricerca: buon senso, interazione con un ambiente, acquisizione di esperienza, comunicazione, ragionamento logico\ldots
\paragraph{Considerazioni} L'intelligenza quindi non è una collezione di tecniche per risolvere problemi \textbf{specifici}, ma per l'informatica consiste nel \textbf{fornire metodologie sistematiche per dotare le macchine di comportamenti intelligenti/\textit{razionali} su problemi generali \textit{difficili}}.
\section{Agenti}
Iniziamo con inquadrare gli \textbf{agenti}. L'approccio moderno dell'IA consiste della costruzione di agenti intelligenti. Questa visione ci offre un quadro di riferimento ed una prospettiva \textbf{diversa} all'analisi dei sistemi software.\\
Il primo obiettivo sarà di costruire agenti per la risoluzione di problemi vista come una \textbf{ricerca in uno spazio di stati} (\textbf{problem solving})
\begin{center}
	\includegraphics[scale=0.7]{agenti.png}
\end{center}
\subsection{Caratteristiche}
Sono qualcosa di più di un modulo software.
\paragraph{Situati} Gli agenti sono \textbf{situati in un ambiente} da cui \textbf{ricevono percezioni} e su cui \textbf{agiscono} mediante \textbf{azioni} (\textbf{attuatori}).
\paragraph{Sociali} Gli agenti hanno \textbf{abilità sociali}: comunicano, collaborano e si difendono da altri agenti.
\paragraph{Credenze, obiettivi, intenzioni\ldots}
\paragraph{Corpo} Gli agenti hanno un \textbf{corpo}, sono \textbf{embodied} fino a considerare i meccanismi delle emozioni.
\subsection{Percezioni e Azioni}
\paragraph{Percezione} Una percezione è un input da sensori.
\paragraph{Sequenza percettiva} Storia \textbf{completa} delle percezioni\\
La \textbf{scelta delle azioni} è \textbf{unicamente determinata dalla sequenza percettiva}.
\paragraph{Funzione Agente} Definisce l'azione da intraprendere per ogni sequenza percettiva e \textbf{descrive completamente l'agente}. Implementata da un \textbf{programma agente}.
\begin{center}
	\textbf{Sequenza Percettiva} $\longrightarrow^f$ \textbf{Azione}
\end{center}
Il compito dell'IA è progettare il programma agente.
\subsection{Agente e ambiente}
\paragraph{Architettura astratta}
\begin{center}
	\includegraphics[scale=0.7]{ambiente.png}
\end{center}
\paragraph{Esempi}
\begin{list}{}{}
	\item \textbf{Agente robotico} Percepisce con camera, microfoni e sensori. Interagisce con motori, voce\ldots
	\item \textbf{Agente finanziario} Percepisce i tassi, le news. Interagisce con acquisti e scambi.
	\item \textbf{Agente di gioco} Percepisce le mosse dell'avversario. Interagisce tramite le proprie mosse.
	\item \textbf{Agente diagnostico} Percepisce i sintomi e le analisi dei pazienti. Interagisce fornendo la diagnosi.
	\item \textbf{Agente web} Percepisce le query utente e le pagine web. Interagisce fornendo i risultati di ricerca.
\end{list}
\subsection{Agenti Razionali}
\paragraph{Agenti razionali} Un agente razionale \textbf{interagisce con l'ambiente in maniera efficace}: "\textit{fa la cosa giusta}". L'agente razionale raggiunge l'obiettivo nella maniera più efficiente.\\
Serve quindi una \textbf{misura di prestazione}, di \textit{come vogliamo che il mondo evolva}, a seconda del problema e considerato l'ambiente.
\begin{list}{}{}
	\item \textbf{Esterna}, perché bisogna definirla \textit{prima} di agire. Non si può definire l'obiettivo dopo aver iniziato ad agire, altrimenti non è significativo.\\
	Esempio: la volpe che non arriva all'uva.
	\item Scelta dal progettista a seconda del problema e considerando l'effetto che ha sull'ambiente.
\end{list}
\paragraph{Razionalità} La razionalità è relativa/dipende da:
\begin{list}{}{}
	\item Misura delle prestazioni
	\item Conoscenze pregresse dell'ambiente
	\item Percezioni presenti e passate (sequenza percettiva)
	\item Capacità dell'agente (le azioni possibili)
\end{list}
\paragraph{Definizione} Un \textbf{agente razionale}, quindi, \textbf{esegue l'azione che massimizza il valore atteso della misura delle prestazioni per ogni sequenza di percezioni}, considerando le sue percezioni passate e la sua conoscenza pregressa.\\
Non si pretende perfezione e conoscenza del futuro, ma massimizzare il risultato \textit{atteso}. Potrebbero essere necessarie azioni di acquisizione di informazioni o esplorative (\textbf{non onniscenza}).\\
Le capacità dell'agente possono essere limitate (\textbf{non onnipotenza}).
\paragraph{Razionalità e apprendimento} Raramente il programmatore può fornire a priori tutta la conoscenza sull'ambiente. L'agente razionale, quindi, \textbf{deve essere in grado di modificare il proprio comportamento con l'esperienza}, cioè con le percezioni passate.\\
Può migliorarsi esplorando, \textbf{apprendendo}, aumentando la propria autonomia per operare in ambienti differenti o mutevoli.
\subsection{Agenti Autonomi} Un agente è \textbf{autonomo quando il suo comportamento dipende dalla sua esperienza}. Se il suo comportamento fosse determinato solo dalla propria conoscenza \textit{built-int} allora sarebbe \textbf{non autonomo} e poco flessibile.
\pagebreak
\section{Ambienti}
Definire un problema per un agente significa \textbf{caratterizzare l'ambiente in cui lavora}, cioè l'\textbf{ambiente operativo}. L'agente razionale è la soluzione del problema.
\subsection{PEAS}
\begin{list}{}{}
	\item \textbf{Performance}, prestazioni
	\item \textbf{Environment}, ambiente
	\item \textbf{Actuators}, attuatori
	\item \textbf{Sensors}, sensori
\end{list}
\paragraph{Esempio} Autista di taxi
\begin{center}
	\begin{tabular}{p{4cm} | p{4cm} | p{4cm} | p{4cm}}
		\textbf{Prestazione} & \textbf{Ambiente} & \textbf{Attuatori} & \textbf{Sensori} \\
		\hline
		Arrivare alla destinazione, sicuro, veloce, ligio alla legge, confortevole, consumo minimo di benzina, profitti massimi & Strada, altri veicoli, clienti & Sterzo, acceleratore, freni, frecce, clacson & Telecamere, sensori, GPS, contachilometri, accelerometro, sensori del motore\ldots
	\end{tabular}
\end{center}
\paragraph{Formulazione PEAS dei problemi}
\begin{center}
	\begin{tabular}{p{3cm} | p{3cm} | p{3cm} | p{3cm} | p{3cm}}
		\textbf{Problema} & \textbf{P} & \textbf{E} & \textbf{A} & \textbf{S} \\
		\hline
		Diagnosi medica & Diagnosi corretta & Pazienti, ospedale & Domande, suggerimenti, test, diagnosi & Sintomi, test clinici, risposte del paziente \\
		\hline
		Analisi immagini & Numero di immagini/zone correttamente classificate & Collezione di fotografie & Etichettatore di zone nell'immagine & Array di pixel \\
		\hline
		Robot "selezionatore" & Numero delle parti correttamente classificate & Nastro trasportatore & Raccogliere le parti e metterle nei cestini & Telecamera (pixel di varia intensità) \\
		\hline
		Giocatore di calcio & Fare più goal dell'avversario & Altri giocatore, campo di calcio, porte & Dare calci al pallone, correre & Locazione del pallone, dei giocatori e delle porte
	\end{tabular}
\end{center}
\subsection{Simulatore di Ambienti}
Uno \textbf{strumento software} con il compito di:
\begin{list}{}{}
	\item Generare gli stimoli per gli agenti
	\item Raccogliere le azioni in risposta
	\item Aggiornare lo stato dell'ambiente
	\item Opzionalmente, attivare altri processi che influenzano l'ambiente
	\item Valutare le prestazioni degli agenti
\end{list}
Gli esperimenti su classi di ambienti (variando le condizioni) sono essenziali per valutare la capacità di generalizzare. La valutazione delle prestazioni è fatta tramite la media su più istanze.
\pagebreak
\subsection{Proprietà dell'Ambiente-Problema}
\begin{list}{-}{}
	\item \textbf{Osservabilità}\\\textbf{Completamente osservabile}: l'apparato percettivo è in grado di dare una conoscenza completa dell'ambiente o almeno tutto quello che serve a decidere l'azione.\\
	\textbf{Parzialmente osservabile}: sono presenti limiti o inaccuratezze nell'apparato sensoriale. (Es. la videocamera di un rover vede solo parte dell'ambiente in un dato istante).
	\item \textbf{Singolo/Multi-Agente}\\
	Distinzione tra agente e non agente: il mondo può cambiare anche attraverso \textbf{eventi}, non necessariamente per le azioni di agenti.\\
	\textbf{Multi-Agente Competitivo}, come gli scacchi: comportamento randomizzato ma razionale.\\
	\textbf{Multi-Agente Cooperativo}, o benigno: stesso obiettivo e comunicazione.
	\item \textbf{Predicibilità}\\
	\textbf{Deterministico}: lo stato successivo è completamente determinato dallo stato corrente e dall'azione.\\
	\textbf{Stocastico}: esistono elementi di incertezza con probabilità associata. Es: guida, tiro in porta.\\
	\textbf{Non deterministico}: si tiene traccia di più stati possibili che sono risultato dell'azione, ma non in base ad una probabilità.
	\item \textbf{Episodico}: l'esperienza dell'agente è divisa in episodi atomici indipendenti. In ambienti episodici non c'è bisogno di pianificare.\\
	\textbf{Sequenziale}: ogni decisione influenza le succesive.
	\item \textbf{Statico}: il mondo non cambia mentre l'agente decide l'azione.\\
	\textbf{Dinamico}: l'ambiente cambia nel tempo, va osservata la contingenza. Tardare equivale a non agire.\\
	\textbf{Semi-dinamico}: l'ambiente non cambia ma la valutazione dell'agente si. Es: scacchi con timer, se non agisco prima dello scadere perdo.
	\item \textbf{Discreto/Continuo}\\
	Lo stato, il tempo, le percezioni e le azioni sono tutti elementi che possono assumere valori discreti o continui.\\
	Combinatoriale (nel discreto) \textit{vs} infinito (nel continuo).
	\item \textbf{Noto/Ignoto}\\
	Distinzione riferita allo stato di conoscenza dell'agente sulle leggi fisiche dell'ambiente. L'\textbf{agente conosce l'ambiente o deve compiere azioni esplorative}?\\
	\textbf{Noto $\neq$ osservabile}: posso giocare a carte coperte, ma con regole note.
\end{list}
\paragraph{Ambienti reali} Parzialmente osservabili, stocastici, sequenziali, dinamici, continui, multi-agente e ignoti.
\pagebreak

\section{Struttura di un Agente}
\begin{center}
\textbf{Agente $=$ Architettura $+$ Programma}\\
Ag: P $\longrightarrow$ Az
\end{center}
L'\textbf{Ag}ente associa \textbf{Az}ioni alle \textbf{P}ercezioni. Il \textbf{programma dell'agente} implementa la funzione \textbf{Ag}.
\paragraph{Programma Agente} Pseudocodice del programma agente.
\begin{center}
\begin{lstlisting}
function Skeleton-Agent(percept) returns action
	static: memory #la memoria del mondo posseduta dall'agente
	memory <- UpdateMemory(memory, percept)
	action <- Choose-Best-Action(memory) #Cuore dell'IA
	memory <- UpdateMemory(memory, action)
	return action
\end{lstlisting}
\end{center}
\subsection{Strutture di Agenti Caratteristici}
\paragraph{Agente basato su tabella} La scelta dell'azione è un accesso ad una tabella che \textbf{associa un'azione ad ogni possibile sequenza di percezioni}.\\
Vari \textbf{problemi}:
\begin{list}{}{}
	\item Le \textbf{dimensioni} possono essere proibitive: per giocare a scacchi, la tabella dovrebbe contenere un numero di righe nell'ordine di $10^{120} >> 10^{80}$ numero di atomi nell'universo osservabile.
	\item \textbf{Difficile da costruire}
	\item \textbf{Nessuna autonomia}
	\item \textbf{Difficile da aggiornare}, apprendimento complesso.
\end{list}
Con le IA vogliamo realizzare \textbf{automi razionali con un programma \textit{compatto}}.

\paragraph{Agente Reattivo Semplice}
\begin{center}
	\includegraphics[scale=0.5]{agreattsemplice.png}
\end{center}
\begin{lstlisting}
function Agente-Reattivo-Semplice(percezione) returns azione
	persistent: regole #insieme di regole condizione-azione (if-then)
	stato <- Interpreta-Input(percezione)
	regola <- Regola-Corrispondente(stato, regole)
	azione <- regola.Azione
	return azione
\end{lstlisting}
\paragraph{Agenti basati su modello}
\begin{center}
	\includegraphics[scale=0.5]{agmodello.png}
\end{center}
\begin{lstlisting}
function Agente-Basato-su-Modello(percezione) returns azione
	persistent:	stato #descrizione dello stato corrente
			modello #conoscenza del mondo
			regole #insieme di regole condizione-azione
			azione #azione piu recente
	stato <- Aggiorna-Stato(stato, azione, percezione, modello)
	regola <- Regola-Corrispondente(stato, regole)
	azione <- regola.Azione
	return azione
\end{lstlisting}
\paragraph{Agenti con obiettivo} Bisogna pianificare una sequenza di azioni per raggiungere l'obiettivo. (In rosso sono indicate le parti aggiunte)
\begin{center}
	\includegraphics[scale=0.5]{agobiettivo.png}
\end{center}
Sono \textbf{guidati da un obiettivo nella scelta che intraprendono}, è stato fornito un \textbf{goal esplicito}: per esempio una città da raggiungere.\\
A volte l'azione migliore dipende dall'obiettivo da raggiungere (\textit{da che parte devo girare?})\\
Devo \textbf{pianificare una sequenza di azioni} per raggiungere l'obiettivo. Sono meno efficienti ma \textbf{più flessibili} rispetto ad un agente reattivo. L'obiettivo può cambiare, non è codificato nelle regole.\\
Esempio classico: ricerca della sequenza di azioni per raggiungere una data destinazione.
\paragraph{Agenti con valutazione di utilità}
\begin{center}
	\includegraphics[scale=0.5]{agvalutazutilita.png}
\end{center}
\textbf{Obiettivi alternativi}, o più modi per raggiungerlo: l'agente deve decidere verso quali muoversi, quindi è \textbf{necessaria una funzione di utilità} che associa ad uno stato obiettivo un numero reale.\\
\textbf{Obiettivi più facilmente raggiungibili di altri}: la funzione di utilità \textbf{tiene conto della probabilità di successo} e/o di ciascun risultato (\textbf{utilità attesa} o media)
\paragraph{Agenti che apprendono}
\begin{center}
	\includegraphics[scale=0.5]{agappr.png}
\end{center}
\begin{list}{}{}
	\item \textbf{Componente di apprendimento}: produce cambiamenti al programma agente. Migliora le prestazioni, adattando i suoi componenti ed apprendendo dall'ambiente
	\item \textbf{Elemento esecutivo}: il programma agente
	\item \textbf{Elemento critico}: osserva e dà feedback sul comportamento
	\item \textbf{Generatore di problemi}: suggerisce nuove situazioni da esplorare
\end{list}
\pagebreak
\subsection{Tipi di rappresentazione}
\paragraph{Stati e transizioni}
\begin{center}
	\includegraphics[scale=0.75]{rapprstatitransizioni.png}
\end{center}
\begin{list}{}{}
	\item \textbf{Rappresentazione atomica} (stati)
	\item \textbf{Rappresntazione fattorizzata} ($+$ variabili e attributi)
	\item \textbf{Rappresentazione strutturata} ($+$ relazioni)
\end{list}

\chapter{Problem Solving}
\section{Agenti Risolutori di Problemi}
\paragraph{Problem Solving} Questi agenti adottano il paradigma della \textbf{risoluzione di problemi come ricerca in uno spazio di stati} (\textbf{problemi solving}). Sono \textbf{agenti con modello} (storia, percezioni) che \textbf{adottano una rappresentazione atomica dello stato}. Sono \textbf{particolari agenti con obiettivo} che \textbf{pianificano l'intera sequenza di azioni} prima di agire.
\subsection{Processo di risoluzione}
\paragraph{Passi da seguire}
\begin{enumerate}
	\item \textbf{Determinazioni dell'obiettivo}: un insieme di stati dove l'obiettivo è soddisfatto.
	\item \textbf{Formulazione del problema}: rappresentazione degli stati e delle azioni.\\
	\textit{Fa parte del design "umano"}.
	\item \textbf{Determinazione della soluzione} mediante ricerca: un piano d'azione
	\item \textbf{Esecuzione del piano}\\
	\textit{Soluzione algoritmica}.
\end{enumerate}
La determinazione dell'obiettivo e la formulazione del problema richiede \textbf{tanta intelligenza}, che in fase di design è \textbf{spostata sull'umano}. Gli algoritmi sono ancora "\textit{stupidi}".
\paragraph{Assunzioni sull'ambiente} \textbf{Statico}, \textbf{osservabile} (so dove sono, es: \textit{viaggio con la mappa}), \textbf{discreto} (insieme finito di azioni possibili), \textbf{deterministico} (una azione $\Rightarrow$ un risultato. L'agente può eseguire il piano "\textit{ad occhi chiusi}", niente può andare storto)
\paragraph{Formulazione del problema} Un problema può essere \textbf{definito formalmente} mediante cinque componenti:
\begin{enumerate}
	\item \textbf{Stato iniziale}
	\item \textbf{Azioni possibili} nello stato \texttt{s}: \texttt{Azioni(s)}
	\item \textbf{Modello di transizione}\\
	\texttt{Risultato}: stato $\times$ azione $\longrightarrow$ stato\\
	\texttt{Risultato(s, a)}: \texttt{s'}, uno stato \textbf{successore}
	\item \textbf{Test obiettivo}: un insieme di stati obiettivo\\
	\texttt{Goal-Test}: stato $\longrightarrow$ \{\texttt{true}, \texttt{false}\}
	\item \textbf{Costo del cammino}: somma dei costi delle azioni (costo dei passi).\\
	Costo di un passo: \texttt{c(s, a, s')}, mai negativo.
\end{enumerate}
1, 2 e 3 \textbf{definiscono \textit{implicitamente} lo spazio degli stati}. Definirlo esplicitamente può essere molto oneroso, come in quasi tutti i problemi di IA.
\pagebreak
\section{Algoritmi di Ricerca}
\textit{Il processo che cerca una sequenza di azioni che raggiunge l'obiettivo è detto \textbf{ricerca}}.
\paragraph{Algoritmi} Gli algoritmi di ricerca prendono in \textbf{input un problema} e \textbf{restituiscono un cammino soluzione}, un cammino che porta dallo stato iniziale allo stato goal.
\paragraph{Misura delle prestazioni} Trova una soluzione? Quanto costa trovarla? Quanto è efficiente la soluzione?
\begin{center}
Costo Totale = Costo della Ricerca $+$ Costo del Cammino Soluzione
\end{center}
Valuteremo algoritmi sul primo, ottimizzando il secondo.
\subsection{Ricerca ad Albero}
Generazione di un \textbf{albero di ricerca sovrapposto allo spazio degli stati}. Ricerca significa \textbf{approfondire l'opzione}, mettendo da parte le altre che verranno riprese se non trovo la soluzione.\\
Quindi l'albero viene generato esplorando i vari nodi partendo dallo stato iniziale. Il nodo è diverso dallo stato: per esempio, in un grafo rappresentante le città, se parto da città A ed esploro l'opzione nodo B, il nodo B avrà come figlio anche città A perché posso tornarci.
\begin{center}
	\includegraphics[scale=0.7]{ricercaalbero.png}
\end{center}
\paragraph{Algoritmo} \textbf{Ricerca ad albero}, ossia senza controllare se i nodi (\textbf{stati}) siano già stati esplorati.

\begin{lstlisting}
function Ricerca-Albero(problema) returns soluzione oppure fallimento
	#Inizializza la frontiera con stato iniziale del problema
	loop do
	if (frontiera vuota) 
		return fallimento
	#Scegli* un nodo foglia da espandere e rimuovilo dalla frontiera
	if (nodo contiene uno stato obiettivo)
		return soluzione corrispondente
	#Espandi il nodo e aggiungi i successori alla frontiera
\end{lstlisting}
$*$ $=$ \textbf{strategia}: quale scegliere? I vari algoritmi si differenziano per la strategia di scelta.\\
\begin{list}{}{Un \textbf{nodo} n è una \textbf{struttura dati con quattro componenti}}
	\item \textbf{Stato}, n.stato
	\item \textbf{Padre}, n.padre
	\item \textbf{Azione} effettuata per generarlo, n.azione
	\item \textbf{Costo} del cammino dal nodo iniziale al nodo, n.costo-cammino\\
	Indicata come g(b) = padre.costo-cammino + costo-passo ultimo)
\end{list}
\paragraph{Frontiera} Lista dei \textbf{nodi in attesa di essere espansi}, cioè \textbf{le foglie} dell'albero di ricerca. Implementata come una coda con operazioni:
\begin{list}{}{}
	\item Vuota(coda)
	\item Pop(coda) estrae l'ultimo elemento (implementa la strategia)
	\item Inserisci(elemento, coda)
\end{list}
Diversi tipi di coda hanno differenti funzioni di inserimento e \textbf{implementano strategie diverse}.
\begin{list}{}{}
	\item \textbf{FIFO} $\rightarrow$ BF\\
	Viene estratto l'elemento più vecchio, cioè in attesa da più tempo. Nuovi nodi aggiunti alla fine
	\item \textbf{LIFO} $\rightarrow$ DF\\
	Viene estratto l'ultimo elemento inserito. Nuovi nodi aggiunti all'inizio
	\item \textbf{Con priorità} $\rightarrow$ UC, altri\ldots\\
	Viene estratto l'elemento con priorità più alta in base ad una funzione di ordinamento. All'aggiunta di un nuovo nodo si riordina.
\end{list}
\paragraph{Strategie non informate}
\begin{list}{}{}
	\item Ricerca in \textbf{ampiezza} (BF)
	\item Ricerca in \textbf{profondità} (DF)
	\item Ricerca in \textbf{profondità limitata} (DL)
	\item Ricerca con \textbf{apprendimento iterativo} (ID)
	\item Ricerca di \textbf{costo uniforme} (UC)
\end{list}
\paragraph{Strategie informate} Anche dette di \textbf{ricerca euristica}: fanno uso di informazioni riguardo la distanza stimata della soluzione.
\paragraph{Valutazione di una strategia}
\begin{list}{}{}
	\item \textbf{Completezza}: se la soluzione esiste viene trovata
	\item \textbf{Ottimalità} (ammissibilità): trova la soluzione migliore, con costo minore
	\item \textbf{Complessità in tempo}: tempo richiesto per trovare la soluzione
	\item \textbf{Complessità in spazio}: memoria richiesta
\end{list}
\subsection{Breadth-First}
\paragraph{Ricerca in ampiezza} Esplorare il grafo dello spazio degli stati a livelli progressivi di stessa profondità. Implementata con una coda FIFO. \textbf{Algoritmo su albero}:
\begin{lstlisting}
function RicercaAmpiezzaA(problema)	returns soluzione oppure fallimento
	nodo = un nodo con stato = problema.stato-iniziale e costo-di-cammino = 0
	#Stati goal-tested alla generazione: maggior efficienza si ferma appena trova goal
	if (problema.TestObiettivo(nodo.Stato)) return Soluzione(nodo)
	frontiera = una coda FIFO con nodo come unico elemento
	loop do
	if (Vuota(frontiera)) return fallimento
	nodo = Pop(frontiera)
	for each azione in problema.Azioni(nodo.Stato) do #Espansione
		figlio = Nodo-Figlio(problema, nodo, azione) #costruttore: vedi AIMA
		if (Problema.TestObiettivo(figlio.Stato)) return Soluzione(figlio)
		frontiera = Inserisci(figlio, frontiera) #frontiera coda FIFO
\end{lstlisting}
\pagebreak
\textbf{Algoritmo su grafo} evitando di espandere stati già esplorati:
\begin{lstlisting}
function RicercaAmpiezzaG(problema) returns soluzione oppure fallimento
	nodo = un nodo con stato = problema.stato-iniziale e costo-di-cammino = 0
	if (problema.TestObiettivo(nodo.Stato)) return Soluzione(nodo)
	frontiera = una coda FIFO con nodo come unico elemento
	esplorati = insieme vuoto #gestisco stati ripetuti
	loop do
	if (Vuota(frontiera)) return fallimento
	nodo = POP(frontiera) #aggiungi nodo.Stato a esplorati
	for each azione in problema.Azioni(nodo.Stato) do
		figlio = Nodo-Figlio(problema, nodo, azione)
		if (figlio.Stato non in esplorati e non in frontiera)
			if (Problema.TestObiettivo(figlio.Stato)) return Soluzione(figlio)
			frontiera = Inserisci(figlio, frontiera) #in coda
\end{lstlisting}

\textbf{Python}
\begin{lstlisting}
def breadth_first_search(problem): """Ricerca-grafo in ampiezza"""
  explored = [] # insieme degli stati gia' visitati (implementato come una lista)
  node = Node(problem.initial_state) #il costo del cammino e' inizializzato nel costruttore del nodo
  if problem.goal_test(node.state):
    return node.solution(explored_set = explored)
  frontier = FIFOQueue() # la frontiera e' una coda FIFO
  frontier.insert(node)
  while not frontier.isempty(): # seleziona il nodo per l'espansione
    node = frontier.pop()
    explored.append(node.state) # inserisce il nodo nell'insieme dei nodi esplorati
    for action in problem.actions(node.state):
      child_node = node.child_node(problem,action)
      if (child_node.state not in explored) and
      (not frontier.contains_state(child_node.state)):
        if problem.goal_test(child_node.state):
        return child_node.solution(explored_set = explored)
      # se lo stato non e' uno stato obiettivo allora inserisci il nodo nella frontiera
      frontier.insert(child_node)
  return None # in questo caso ritorna con fallimento
\end{lstlisting}
\paragraph{Analisi della complessità spazio-temporale} Assumiamo:
\begin{list}{}{}
	\item \textbf{b} = fattore di ramificazione (\textbf{b}ranching)
	\item \textbf{d} = profondità del nodo obiettivo più superficiale (\textbf{d}epth)\\
	Più vicino all'iniziale
	\item \textbf{m} = lunghezza massima dei cammini nello spazio degli stati (\textbf{m}ax)
\end{list}
Analisi:
\begin{list}{}{}
	\item Strategia \textbf{completa}
	\item Strategia \textbf{ottimale} \textit{se gli operatori hanno tutti lo stesso costo k} cioè g(n) = k $\cdot$ depth(n), dove g(n) è il costo del cammino per arrivare ad n.
	\item Complessità nel tempo (nodi generati)\\
	T(b, d) = b + b$^2$ + \ldots + b$^d$ = O(b$^d$), con b figli per ogni nodo.
	\item Complessità nello spazio (nodi in memoria): O(b$^d$)
\end{list}
\end{document}
